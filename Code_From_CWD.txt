
###### FILENAME: analysis_main.py ######

import logging
import time
from config import Config
from utils.logging_setup import setup_logging
from analysis.clip_analysis import process_clip_images
from analysis.llm_analysis import process_llm_images
from utils.json_utils import process_existing_json_files
from utils.api_utils import test_api

def main():
    """
    Main function to run the analysis.
    """
    config = Config()
    setup_logging(config)

    logging.info("### Processing New Batch ###")

    # Verify the API before starting the image processing
    api_base_url = config.api_base_url
    timeout = config.timeout

    for attempt in range(3):
        if test_api(api_base_url, timeout):
            logging.info("API is responsive and working.")
            process_clip_images(config, api_base_url, timeout)
            process_llm_images(config, api_base_url, timeout)
            break
        else:
            logging.warning("API at %s is not responsive. Attempt %d failed.", api_base_url, attempt + 1)
            time.sleep(2 ** attempt)  # Exponential backoff
    else:
        logging.error("API at %s is not responsive after 3 attempts. Skipping.", api_base_url)

    # Process existing JSON files to generate prompt lists
    process_existing_json_files(config)

if __name__ == "__main__":
    main()


###### FILENAME: config.py ######

import logging
import os
import configparser
from constants import DEFAULTS

def mask_api_key(api_key):
    """Mask the API key for secure logging."""
    if len(api_key) < 6:
        return "*" * len(api_key)
    return api_key[:3] + "*" * (len(api_key) - 6) + api_key[-3:]

class Config:
    """
    Configuration handler to load and manage application settings.
    """

    def __init__(self, config_file='config.ini'):
        self.config_file = config_file
        self.config = configparser.RawConfigParser()
        self.load_config()

    def load_config(self):
        """
        Load configuration from the config file.
        """
        if not os.path.exists(self.config_file):
            self.create_default_config()
        self.config.read(self.config_file)

        # General Settings
        self.image_directory = self.config.get('DEFAULT', 'IMAGE_DIRECTORY', fallback=DEFAULTS['DEFAULT']['IMAGE_DIRECTORY'])
        self.output_directory = self.config.get('DEFAULT', 'OUTPUT_DIRECTORY', fallback=DEFAULTS['DEFAULT']['OUTPUT_DIRECTORY'])
        self.api_base_url = self.config.get('DEFAULT', 'API_BASE_URL', fallback=DEFAULTS['DEFAULT']['API_BASE_URL'])
        self.api_key = self.get_openai_api_key()
        self.timeout = self.config.getint('DEFAULT', 'TIMEOUT', fallback=DEFAULTS['DEFAULT']['TIMEOUT'])

        # Logging Settings
        self.logging_level = self.config.get('DEFAULT', 'LOGGING_LEVEL', fallback=DEFAULTS['DEFAULT']['LOGGING_LEVEL'])
        self.logging_format = self.config.get('DEFAULT', 'LOGGING_FORMAT', fallback=DEFAULTS['DEFAULT']['LOGGING_FORMAT'])
        self.log_to_console = self.config.getboolean('DEFAULT', 'LOG_TO_CONSOLE', fallback=DEFAULTS['DEFAULT']['LOG_TO_CONSOLE'])
        self.log_to_file = self.config.getboolean('DEFAULT', 'LOG_TO_FILE', fallback=DEFAULTS['DEFAULT']['LOG_TO_FILE'])
        self.log_file = self.config.get('DEFAULT', 'LOG_FILE', fallback=DEFAULTS['DEFAULT']['LOG_FILE'])
        self.log_mode = self.config.get('DEFAULT', 'LOG_MODE', fallback=DEFAULTS['DEFAULT']['LOG_MODE'])
        self.log_api_communication = self.config.getboolean('DEFAULT', 'LOG_API_COMMUNICATION', fallback=DEFAULTS['DEFAULT']['LOG_API_COMMUNICATION'])

        # File Handling Settings
        self.create_individual_files = self.config.getboolean('DEFAULT', 'CREATE_INDIVIDUAL_FILES', fallback=DEFAULTS['DEFAULT']['CREATE_INDIVIDUAL_FILES'])
        self.create_prompt_list = self.config.getboolean('DEFAULT', 'CREATE_PROMPT_LIST', fallback=DEFAULTS['DEFAULT']['CREATE_PROMPT_LIST'])
        self.create_master_files = self.config.getboolean('DEFAULT', 'CREATE_MASTER_FILES', fallback=DEFAULTS['DEFAULT']['CREATE_MASTER_FILES'])
        self.list_file_mode = self.config.get('DEFAULT', 'LIST_FILE_MODE', fallback=DEFAULTS['DEFAULT']['LIST_FILE_MODE'])

        # Model Settings
        self.model = self.config.get('DEFAULT', 'MODEL', fallback=DEFAULTS['DEFAULT']['MODEL'])
        self.model_nickname = self.config.get('DEFAULT', 'MODEL_NICKNAME', fallback=self.model)
        self.caption_types = self.get_config_list('CAPTION_TYPES')

        # Filename-related variables
        self.master_analysis_filename = self.config.get('DEFAULT', 'MASTER_ANALYSIS_FILENAME', fallback=DEFAULTS['DEFAULT']['MASTER_ANALYSIS_FILENAME'])

        # New option for processing JSON files without images
        self.process_json_without_images = self.config.getboolean('DEFAULT', 'PROCESS_JSON_WITHOUT_IMAGES', fallback=DEFAULTS['DEFAULT']['PROCESS_JSON_WITHOUT_IMAGES'])

        # LLM Settings
        self.selected_prompts = self.get_config_list('SELECTED_PROMPT')
        self.llm_system_content = self.config.get('DEFAULT', 'LLM_SYSTEM_CONTENT', fallback=DEFAULTS['DEFAULT']['LLM_SYSTEM_CONTENT'])
        self.llm_model = self.config.get('DEFAULT', 'LLM_MODEL', fallback=DEFAULTS['DEFAULT']['LLM_MODEL'])

        # Multiple LLMs configuration
        self.llms = {}
        for i in range(2, 5):  # Assuming we have up to 4 LLMs, with OpenAI hardcoded as the first
            llm_key = f'LLM_{i}'
            if self.config.has_section(llm_key):
                self.llms[llm_key] = {
                    'enabled': self.config.getboolean(llm_key, 'ENABLED', fallback=False),
                    'api_url': self.config.get(llm_key, 'API_URL', fallback=''),
                    'api_key': self.config.get(llm_key, 'API_KEY', fallback='')
                }
                logging.debug("LLM configuration for %s: %s" % (llm_key, self.llms[llm_key]))

    def get_config_list(self, key):
        """
        Get a list of values from a comma-separated config entry.

        :param key: Configuration key.
        :return: List of values.
        """
        return [item.strip() for item in self.config.get('DEFAULT', key, fallback='').split(',')]

    def create_default_config(self):
        """
        Create a default configuration file if it does not exist.
        """
        with open(self.config_file, 'w', encoding='utf-8') as configfile:
            for section, options in DEFAULTS.items():
                configfile.write(f"[{section}]\n")
                for key, value in options.items():
                    configfile.write(f"{key} = {value}\n")
                configfile.write("\n")
        self.config.read(self.config_file)

    def get_openai_api_key(self):
        """
        Get the OpenAI API key from the environment variable.
        """
        api_key = os.getenv('OPENAI_API_KEY', '')
        if not api_key:
            logging.error("OpenAI API Key not found in environment.")
        logging.debug(f"Fetched OpenAI API Key: {mask_api_key(api_key)}")
        return api_key


###### FILENAME: constants.py ######

DEFAULTS = {
    'DEFAULT': {
        'IMAGE_DIRECTORY': 'Images',
        'OUTPUT_DIRECTORY': 'Output',
        'API_BASE_URL': 'http://127.0.0.1:7864',
        'API_KEY': '',
        'TIMEOUT': 40,
        'LOGGING_LEVEL': 'DEBUG',
        'LOGGING_FORMAT': '%(message)s',
        'LOG_TO_CONSOLE': True,
        'LOG_TO_FILE': True,
        'LOG_FILE': 'Log.log',
        'LOG_MODE': 'w',
        'LOG_API_COMMUNICATION': True,
        'MODEL': 'ViT-g-14/laion2B-s34B-b88K',
        'CAPTION_TYPES': 'caption,best,fast,classic,negative',
        'ANALYSIS_TYPE': 1,
        'LLM_API_BASE_URL': 'https://api.openai.com/v1/chat/completions',
        'LLM_API_KEY': '',
        'LLM_API_HEADERS': '{"Content-Type": "application/json"}',
        'LLM_SYSTEM_CONTENT': 'Your default system content here',
        'LLM_MODEL': 'gpt-4o',  # Default LLM model
        'SELECTED_PROMPT': 1,
        'IMAGE_FILE_EXTENSIONS': '.png,.jpg,.jpeg',
        'CREATE_INDIVIDUAL_FILES': True,  # Ensure this key is included
        'CREATE_PROMPT_LIST': True,
        'CREATE_MASTER_FILES': True,
        'LIST_FILE_MODE': 'w',
        'MASTER_ANALYSIS_FILENAME': 'master_analysis.json',
        'PROCESS_JSON_WITHOUT_IMAGES': False
    },
    'Prompt Options': {
        '1': {
            'PROCESS_NAME': 'DetailedDescription',
            'PROMPT_TEXT': (
                "Provide a detailed description of the image's content, focusing on essential elements such as key figures, objects, setting, and any significant interactions. "
                "You should not mention anything associated with style like colors, artist names or techniques. "
                "Just describe what is happening in the scene. Ensure the description is clear and comprehensive enough for someone who has never seen the image to accurately recreate it in a painting. "
                "Each answer should be one paragraph per image only."
            ),
            'TEMPERATURE': 0.7,
            'MAX_TOKENS': 100
        },
        '2': {
            'PROCESS_NAME': 'EnhanceDetails',
            'PROMPT_TEXT': "Enhance the image details, making colors more vibrant and edges sharper.",
            'TEMPERATURE': 0.6,
            'MAX_TOKENS': 150
        },
        '3': {
            'PROCESS_NAME': 'ObjectInteraction',
            'PROMPT_TEXT': "Remove any style or art references from the image description, focusing purely on the objects and interactions.",
            'TEMPERATURE': 0.5,
            'MAX_TOKENS': 200
        },
        '4': {
            'PROCESS_NAME': 'DeepDescription',
            'PROMPT_TEXT': "Provide a deep description of the image, including subtle details and background elements.",
            'TEMPERATURE': 0.8,
            'MAX_TOKENS': 250
        },
        '5': {
            'PROCESS_NAME': 'HistoricalAnalysis',
            'PROMPT_TEXT': "Analyze the image for any historical or cultural references, providing context and background information.",
            'TEMPERATURE': 0.9,
            'MAX_TOKENS': 300
        }
    },
    'LLM_1': {
        'ENABLED': True,
        'API_URL': 'https://api.openai.com/v1/chat/completions',
        'API_KEY': ''  # Will be fetched from the environment variable 'OPENAI_API_KEY'
    },
    'LLM_2': {
        'ENABLED': False,
        'API_URL': 'https://example.com/api1',
        'API_KEY': ''
    },
    'LLM_3': {
        'ENABLED': False,
        'API_URL': 'https://example.com/api2',
        'API_KEY': ''
    },
    'LLM_4': {
        'ENABLED': False,
        'API_URL': 'https://example.com/api3',
        'API_KEY': ''
    }
}



###### FILENAME: test_llm.py ######

import os
import base64
import json
import logging
import requests

# Set up logging for the test
logging.basicConfig(level=logging.DEBUG)

# Test configuration
TEST_OPENAI_API_KEY = os.getenv('TEST_OPENAI_API_KEY', 'sk-proj-CSugxHuYq4dgiIEJjQo3T3BlbkFJimzWdOKu0UR9ZbHYvT2W')  # Replace with your actual OpenAI API key
TEST_IMAGE_PATH = r"C:\Users\jiml\Dropbox\#AIArt\SourceCode\CODE_CLIP_Analysis\Images\1\RANDOS (30).png"
TEST_PROMPT_TEXT = "What's in this image?"
TEST_MODEL = "gpt-4o"
TEST_TEMPERATURE = 0.7
TEST_MAX_TOKENS = 300

def encode_image(image_path):
    """Encode an image file to a base64 string."""
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode('utf-8')

def test_llm_analysis():
    # Set the OpenAI API key in environment variable
    os.environ['OPENAI_API_KEY'] = TEST_OPENAI_API_KEY

    # Encode the image to base64
    base64_image = encode_image(TEST_IMAGE_PATH)

    # Create the headers
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {os.getenv('OPENAI_API_KEY')}"
    }

    # Create the data payload
    payload = {
        "model": TEST_MODEL,
        "messages": [
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": TEST_PROMPT_TEXT},
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/jpeg;base64,{base64_image}"
                        }
                    }
                ]
            }
        ],
        "temperature": TEST_TEMPERATURE,
        "max_tokens": TEST_MAX_TOKENS,
        "top_p": 1.0,
        "frequency_penalty": 0.0,
        "presence_penalty": 0.0
    }

    # Log the data payload excluding the 'messages' content
    logging.debug(f"Created data payload for LLM request: {json.dumps({k: v for k, v in payload.items() if k != 'messages'}, indent=2)}")

    # Send the request
    response = requests.post("https://api.openai.com/v1/chat/completions", headers=headers, json=payload)

    # Print the response
    if response.status_code == 200:
        print("Response received:")
        print(response.json())
    else:
        logging.error(f"Request failed: {response.json()}")
        print("No response received.")

if __name__ == "__main__":
    test_llm_analysis()


