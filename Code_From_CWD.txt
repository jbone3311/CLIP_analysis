
###### FILENAME: analysis_interrogate.py ######

"""
Parameters:
    image_path (str): (Required) Path to the image file.
    --api_base_url (str): Base URL of the CLIP API. Default is http://localhost:7860.
    --model (str): Model name for analysis and prompt generation. Default is ViT-L-14.
    --modes (List[str]): Prompt modes to generate. Choose from 'best', 'fast', 'classic', 'negative', 'caption'. Default is all.
    --output (str): Filename for the JSON output. Default is analysis_results.json.

Example:
    python analysis_interrogate.py test.png --modes best fast --output output.json
"""

import requests
import base64
import os
import json
import argparse
from typing import List, Dict, Any
from dotenv import load_dotenv

# Load environment variables from .env file
load_dotenv()

# Load status messages from .env or set default words
EMOJI_SUCCESS = os.getenv("EMOJI_SUCCESS", "SUCCESS")
EMOJI_WARNING = os.getenv("EMOJI_WARNING", "WARNING")
EMOJI_ERROR = os.getenv("EMOJI_ERROR", "ERROR")
EMOJI_INFO = os.getenv("EMOJI_INFO", "INFO")
EMOJI_PROCESSING = os.getenv("EMOJI_PROCESSING", "PROCESSING")
EMOJI_START = os.getenv("EMOJI_START", "START")
EMOJI_COMPLETE = os.getenv("EMOJI_COMPLETE", "COMPLETE")

def encode_image_to_base64(image_path: str) -> str:
    """
    Encodes an image file to a base64 string.

    Args:
        image_path (str): The path to the image file.

    Returns:
        str: The base64 encoded string of the image.
    """
    try:
        with open(image_path, "rb") as image_file:
            return base64.b64encode(image_file.read()).decode('utf-8')
    except Exception as e:
        raise FileNotFoundError(f"Unable to encode image. Error: {e}")

def save_json(data: Dict[str, Any], filename: str):
    """
    Saves data to a JSON file.

    Args:
        data (dict): The data to save.
        filename (str): The name of the file to save the data to.
    """
    try:
        with open(filename, 'w') as f:
            json.dump(data, f, indent=4)
        print(f"{EMOJI_SUCCESS} Saved output to {filename}")
    except Exception as e:
        raise IOError(f"Failed to save JSON to {filename}. Error: {e}")

def analyze_image(image_path: str, api_base_url: str, model: str, timeout: int = 60) -> Dict[str, Any]:
    """
    Sends an image to the CLIP API for analysis.

    Args:
        image_path (str): The path to the image file.
        api_base_url (str): The base URL of the API.
        model (str): The model name to use for analysis.
        timeout (int): The timeout for the API request (default is 60 seconds).

    Returns:
        dict: The JSON response from the API containing analysis results.
    """
    image_base64 = encode_image_to_base64(image_path)
    
    payload = {
        "image": image_base64,
        "model": model
    }
    
    headers = {"Content-Type": "application/json"}
    
    try:
        response = requests.post(
            f"{api_base_url}/interrogator/analyze",
            json=payload,
            headers=headers,
            timeout=timeout
        )
        response.raise_for_status()
        return response.json()
    except requests.RequestException as e:
        raise ConnectionError(f"API request failed during analysis. Error: {e}")

def prompt_image(image_path: str, api_base_url: str, model: str, modes: List[str], timeout: int = 60) -> Dict[str, Any]:
    """
    Sends an image to the CLIP API to generate prompts.

    Args:
        image_path (str): The path to the image file.
        api_base_url (str): The base URL of the API.
        model (str): The model name to use for generating prompts.
        modes (List[str]): List of modes for prompt generation (e.g., 'fast', 'best').
        timeout (int): The timeout for the API request (default is 60 seconds).

    Returns:
        dict: The JSON response from the API containing prompt results.
    """
    image_base64 = encode_image_to_base64(image_path)
    prompts = {}

    headers = {"Content-Type": "application/json"}

    for mode in modes:
        payload = {
            "image": image_base64,
            "model": model,
            "mode": mode
        }

        try:
            response = requests.post(
                f"{api_base_url}/interrogator/prompt",
                json=payload,
                headers=headers,
                timeout=timeout
            )
            response.raise_for_status()
            prompts[mode] = response.json()
        except requests.RequestException as e:
            print(f"{EMOJI_ERROR} Failed to get prompt for mode '{mode}'. Error: {e}")
            prompts[mode] = {"error": str(e)}
    
    return prompts

def parse_arguments() -> argparse.Namespace:
    """
    Parses command-line arguments.

    Returns:
        argparse.Namespace: Parsed arguments.
    """
    parser = argparse.ArgumentParser(
        description="Process images to generate prompts and perform analysis using the CLIP API."
    )
    
    parser.add_argument(
        "image_path",
        type=str,
        help="Path to the image file to be processed."
    )
    
    parser.add_argument(
        "--api_base_url",
        type=str,
        default="http://localhost:7860",
        help="Base URL of the CLIP API (default: http://localhost:7860)."
    )
    
    parser.add_argument(
        "--model",
        type=str,
        default="ViT-L-14",
        help="Model name to use for analysis and prompt generation (default: ViT-L-14)."
    )
    
    parser.add_argument(
        "--modes",
        type=str,
        nargs='+',
        choices=['best', 'fast', 'classic', 'negative', 'caption'],
        default=['best', 'fast', 'classic', 'negative', 'caption'],
        help="Prompt modes to generate. Choose from 'best', 'fast', 'classic', 'negative', 'caption'. Default is all."
    )
    
    parser.add_argument(
        "--output",
        type=str,
        default="analysis_results.json",
        help="Filename for the JSON output (default: analysis_results.json)."
    )
    
    return parser.parse_args()

def main():
    args = parse_arguments()
    
    image_path = args.image_path
    api_base_url = args.api_base_url
    model = args.model
    modes = args.modes
    output_filename = args.output
    
    # Verify that the image file exists
    if not os.path.isfile(image_path):
        print(f"{EMOJI_ERROR} Image file '{image_path}' not found.")
        return
    
    results = {
        "image": os.path.abspath(image_path),
        "model": model,
        "prompts": {},
        "analysis": {}
    }
    
    # Generate prompts
    if modes:
        print(f"{EMOJI_PROCESSING} Generating prompts for modes: {', '.join(modes)}")
        try:
            prompts = prompt_image(image_path, api_base_url, model, modes)
            results["prompts"] = prompts
        except Exception as e:
            print(f"{EMOJI_ERROR} An error occurred during prompt generation: {e}")
    
    # Perform analysis
    print(f"{EMOJI_PROCESSING} Performing image analysis.")
    try:
        analysis = analyze_image(image_path, api_base_url, model)
        results["analysis"] = analysis
    except Exception as e:
        print(f"{EMOJI_ERROR} An error occurred during analysis: {e}")
    
    # Save results to JSON
    try:
        save_json(results, output_filename)
    except Exception as e:
        print(f"{EMOJI_ERROR} Failed to save results: {e}")

if __name__ == "__main__":
    main()



###### FILENAME: analysis_LLM.py ######

#!/usr/bin/env python3
"""
LLMAnalyzer Standalone Script

This script analyzes an image using a selected LLM (Language Model) API.
It accepts prompts directly or via prompt IDs defined in a LLM_Prompts.json file,
sends requests to the API, and generates a JSON file with the results.

Usage:
    python analysis_LLM.py <image_path> --prompt <prompt> --model <model_number> [--output <output_file>] [--debug]

Arguments:
    image_path: Path to the image file to be processed.
    --prompt: Comma-separated prompts or prompt IDs (e.g., 'Describe the image, P1, P2'). Use 'list' to display all prompts.
    --model: Model number for analysis (1-N) or 'list' to display all models.
    --output: Optional output file path for the JSON results.
    --debug: Enable debug logging.

Example:
    python analysis_LLM.py test.png --prompt "P1" --model 1 --output results.json

To list all available models:
    python analysis_LLM.py --model list

To list all available prompts:
    python analysis_LLM.py --prompt list
"""

import os
import logging
import requests
import argparse
import json
import base64
from typing import Optional, Dict, Any, List
from dotenv import load_dotenv

# Load environment variables from .env file
load_dotenv()

# Load status messages from .env or set default words
EMOJI_SUCCESS = os.getenv("EMOJI_SUCCESS", "SUCCESS")
EMOJI_WARNING = os.getenv("EMOJI_WARNING", "WARNING")
EMOJI_ERROR = os.getenv("EMOJI_ERROR", "ERROR")
EMOJI_INFO = os.getenv("EMOJI_INFO", "INFO")
EMOJI_PROCESSING = os.getenv("EMOJI_PROCESSING", "PROCESSING")
EMOJI_START = os.getenv("EMOJI_START", "START")
EMOJI_COMPLETE = os.getenv("EMOJI_COMPLETE", "COMPLETE")

# Load models from .env
MODELS = []
model_count = 1
while True:
    model_name = os.getenv(f'LLM_{model_count}_TITLE')
    model_api_url = os.getenv(f'LLM_{model_count}_API_URL')
    model_api_key = os.getenv(f'LLM_{model_count}_API_KEY')
    model_model = os.getenv(f'LLM_{model_count}_MODEL')
    if not model_name or not model_api_url or not model_model:
        break
    MODELS.append({
        'number': model_count,
        'name': model_name,
        'api_url': model_api_url,
        'api_key': model_api_key,
        'model': model_model
    })
    model_count += 1

# Load prompts from LLM_Prompts.json
PROMPTS_FILE = 'LLM_Prompts.json'

if not os.path.exists(PROMPTS_FILE):
    # Create a sample LLM_Prompts.json file if it doesn't exist
    sample_prompts = {
        "PROMPT1": {
            "TITLE": "Detailed Image Description",
            "PROMPT_TEXT": "You will be given an image to describe in detail. Your task is to provide a comprehensive and accurate description of the contents of the image.\n\nFollow these steps to describe the image:\n\n1. Begin by identifying the main subject or focus of the image. What immediately draws your attention?\n\n2. Describe the overall scene or setting. Is it indoors or outdoors? What time of day does it appear to be?\n\n3. Provide details about the main elements in the image, including:\n   - People: Describe their appearance, clothing, actions, and expressions\n   - Objects: Identify and describe key objects, their colors, sizes, and positions\n   - Animals: If present, describe their species, actions, and appearance\n   - Nature: Describe any natural elements like plants, trees, water bodies, or landscapes\n   - Buildings or structures: Describe their architecture, size, and condition\n\n4. Pay attention to colors, lighting, and atmosphere. How do these elements contribute to the overall mood or feel of the image?\n\n5. Describe any text or signage visible in the image.\n\n6. Note any unusual or striking features that stand out.\n\n7. If relevant, describe the composition of the image, including foreground, middle ground, and background elements.\n\n8. If the image depicts an action or event, describe what appears to be happening.\n\nProvide your description in clear, concise language. Be as objective as possible, focusing on what you can actually see rather than making assumptions or interpretations.\n\nIf any part of the image is unclear or difficult to discern, mention this in your description.\n\nIf for any reason you are unable to process or analyze the image, please state this clearly and explain why (e.g., \"I'm sorry, but I am unable to view or analyze the image provided.\").\n\nPresent your final description in detail so a blind person can see the image and an artist can paint it.",
            "TEMPERATURE": 0.7,
            "MAX_TOKENS": 1000
        },
        "PROMPT2": {
            "TITLE": "Art Critique from Multiple Perspectives",
            "PROMPT_TEXT": "You are an art critic tasked with providing a comprehensive critique of an image from multiple perspectives. Your goal is to analyze the image visually, interpret its meaning, and describe how it appears and what it inspires from different viewpoints.\n\nExamine the image carefully and provide a critique from each of the following perspectives:\n\n1. Artist\n2. Gallery owner\n3. Curator\n4. 12-year-old\n5. 19-year-old\n6. 50-year-old\n\nFor each perspective, consider the following aspects:\n- Visual elements (composition, color, style, technique)\n- Emotional impact\n- Potential meaning or symbolism\n- How it relates to current trends or historical context (if applicable)\n- Personal interpretation based on the specific perspective\n\nStructure your response as follows:\n\n<critique>\n<artist_perspective>\n[Provide the artist's critique here]\n</artist_perspective>\n\n<gallery_owner_perspective>\n[Provide the gallery owner's critique here]\n</gallery_owner_perspective>\n\n<curator_perspective>\n[Provide the curator's critique here]\n</curator_perspective>\n\n<twelve_year_old_perspective>\n[Provide the 12-year-old's critique here]\n</twelve_year_old_perspective>\n\n<nineteen_year_old_perspective>\n[Provide the 19-year-old's critique here]\n</nineteen_year_old_perspective>\n\n<fifty_year_old_perspective>\n[Provide the 50-year-old's critique here]\n</fifty_year_old_perspective>\n</critique>\n\nEnsure that each perspective's critique is distinct and reflects the unique viewpoint of that particular role or age group. Be creative and insightful in your analysis, while remaining respectful and constructive in your critiques.",
            "TEMPERATURE": 0.8,
            "MAX_TOKENS": 1500
        }
    }
    with open(PROMPTS_FILE, 'w') as f:
        json.dump(sample_prompts, f, indent=4)

with open(PROMPTS_FILE, 'r') as f:
    PROMPTS = json.load(f)

class LLMAnalyzer:
    def __init__(self, api_base_url: str, api_key: str, model: str, title: str = "", debug: bool = False):
        self.api_base_url = api_base_url
        self.api_key = api_key
        self.model = model
        self.title = title
        self.debug = debug
        if self.debug:
            logging.debug(f"{EMOJI_INFO} LLMAnalyzer initialized with model {model} and title '{title}'")

    def process_image(self, image_path: str, prompts: List[str], output_file: Optional[str] = None):
        logging.info(f"{EMOJI_PROCESSING} Processing image: {image_path}")
        with open(image_path, "rb") as image_file:
            image_data = base64.b64encode(image_file.read()).decode("utf-8")

        results = []
        for prompt in prompts:
            prompt_details = PROMPTS.get(prompt, {})
            prompt_text = prompt_details.get('PROMPT_TEXT', prompt)
            temperature = float(prompt_details.get('TEMPERATURE', 0.7))
            max_tokens = int(prompt_details.get('MAX_TOKENS', 1000))

            payload = {
                "model": self.model,
                "messages": [
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": prompt_text},
                            {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{image_data}"}}
                        ]
                    }
                ],
                "temperature": temperature,
                "max_tokens": max_tokens
            }

            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json"
            }

            response = requests.post(self.api_base_url, headers=headers, json=payload)

            if response.status_code == 200:
                logging.info(f"{EMOJI_SUCCESS} Prompt '{prompt}' processed successfully.")
                result = response.json()
                results.append({
                    "prompt": prompt,
                    "result": result
                })
            else:
                logging.error(f"{EMOJI_ERROR} Failed to process prompt '{prompt}'. Status code: {response.status_code}")
                logging.error(f"{EMOJI_ERROR} Response: {response.text}")
                results.append({
                    "prompt": prompt,
                    "error": response.text
                })

        if output_file:
            with open(output_file, "w") as f:
                json.dump(results, f, indent=4)
            logging.info(f"{EMOJI_COMPLETE} Results saved to {output_file}")
        else:
            print(json.dumps(results, indent=4))

def list_models(models: List[Dict[str, Any]]):
    """
    Lists all available models with their information (excluding API keys).

    Args:
        models (List[Dict[str, Any]]): List of model dictionaries.
    """
    print(f"{EMOJI_INFO} Available Models:")
    for model in models:
        print(f"  {EMOJI_INFO} Model {model['number']}: {model['name']}")
        print(f"      API URL: {model['api_url']}")
        print(f"      Model: {model['model']}\n")

def list_prompts(prompts: Dict[str, Dict[str, Any]]):
    """
    Lists all available prompts defined in the LLM_Prompts.json file.

    Args:
        prompts (Dict[str, Dict[str, Any]]): Dictionary of prompt IDs and their details.
    """
    if not prompts:
        print(f"{EMOJI_WARNING} No prompts found in the LLM_Prompts.json file.")
        return

    print(f"{EMOJI_INFO} Available Prompts:")
    for prompt_id, prompt_details in sorted(prompts.items()):
        first_line = prompt_details['PROMPT_TEXT'].splitlines()[0]
        print(f"  {EMOJI_INFO} {prompt_id}: {prompt_details['TITLE']} - {first_line}... (Temperature: {prompt_details['TEMPERATURE']}, Max Tokens: {prompt_details['MAX_TOKENS']})")

def main():
    # Parse command-line arguments
    parser = argparse.ArgumentParser(
        description="Analyze an image using a selected LLM (Language Model) API and generate a JSON file with the results."
    )
    parser.add_argument(
        "image_path",
        type=str,
        nargs='?',
        help="Path to the image file to be processed."
    )
    parser.add_argument(
        "--prompt",
        type=str,
        help="Comma-separated prompts or prompt IDs (e.g., 'Describe the image, P1, P2'). Use 'list' to display all prompts."
    )
    parser.add_argument(
        "--model",
        type=str,
        help=f"Model number for analysis (1-{len(MODELS)}) or 'list' to display all models."
    )
    parser.add_argument(
        "--output",
        type=str,
        help="Optional output file path for the JSON results."
    )
    parser.add_argument(
        "--debug",
        action="store_true",
        help="Enable debug logging."
    )

    args = parser.parse_args()

    # Configure root logger
    logging.basicConfig(
        level=logging.DEBUG if args.debug else logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )

    # Handle --model list and --prompt list
    if args.model and args.model.lower() == 'list':
        list_models(MODELS)

    if args.prompt and args.prompt.lower() == 'list':
        list_prompts(PROMPTS)

    # If either --model or --prompt is 'list', and no other arguments, exit
    if (args.model and args.model.lower() == 'list') or (args.prompt and args.prompt.lower() == 'list'):
        exit(0)

    # Ensure required arguments are provided for analysis
    if not args.image_path or not args.prompt or not args.model:
        parser.error("the following arguments are required for analysis: image_path, --prompt, --model")

    # Validate model number
    try:
        model_number = int(args.model)
        selected_model = next((model for model in MODELS if model['number'] == model_number), None)
        if not selected_model:
            logging.error(f"{EMOJI_ERROR} Invalid model number: {model_number}. Use '--model list' to see available models.")
            exit(1)
    except ValueError:
        logging.error(f"{EMOJI_ERROR} Invalid model value: {args.model}. It should be an integer between 1 and {len(MODELS)} or 'list'.")
        exit(1)

    # Initialize LLMAnalyzer
    analyzer = LLMAnalyzer(
        api_base_url=selected_model['api_url'],
        api_key=selected_model['api_key'],
        model=selected_model['model'],
        title=selected_model['name'],
        debug=args.debug
    )

    # Process the image
    prompts = [p.strip() for p in args.prompt.split(',')]
    analyzer.process_image(args.image_path, prompts, args.output)

if __name__ == "__main__":
    main()


###### FILENAME: analysis_main.py ######

import argparse
import logging
from config import Config
from clip_analyzer import CLIPAnalyzer
from llm_analyzer import LLMAnalyzer

def main():
    parser = argparse.ArgumentParser(description="Analyze images using LLM.")
    parser.add_argument("image_path", type=str, help="Path to the image file.")
    parser.add_argument("--prompt", type=str, help="The prompt to be used for analysis.")
    parser.add_argument("--model", type=int, required=True, help="Model number for analysis (1-5).")
    args = parser.parse_args()

    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
    config = Config()

    logging.info("### Processing New Batch ###")

    if config.clip_enabled:
        logging.info("Running CLIP Analyzer...")
        clip_analyzer = CLIPAnalyzer(config)
        clip_analyzer.process_images()

    if config.enable_llm_analysis:  # Check if LLM analysis is enabled
        logging.info("Running LLM Analyzer...")
        llm_analyzer = LLMAnalyzer(config)
        llm_analyzer.process_images(args.image_path, args.prompt, args.model)  # Pass the model number

    logging.info("Finished processing")

if __name__ == "__main__":
    main()


###### FILENAME: analyzer.py ######

import os
import json
import logging
import time
from abc import ABC, abstractmethod
from typing import Dict, List, Tuple
from image_utils import generate_unique_code
import json_utils

class Analyzer(ABC):
    def __init__(self, directory: str):
        self.directory = directory
        self.image_extensions: Tuple[str, ...] = ('.jpg', '.jpeg', '.png')

    @abstractmethod
    def analyze_image(self, image_path: str) -> Dict:
        pass

    def process_directory(self) -> None:
        start_time = time.time()
        existing_files = self.get_existing_json_files()

        total_images, processed_images = self._process_images(existing_files)

        self._log_processing_summary(total_images, processed_images, start_time)

    def _process_images(self, existing_files: List[str]) -> Tuple[int, int]:
        total_images, processed_images = 0, 0

        for image_path in self.get_image_files():
            total_images += 1
            if json_utils.should_process_file(image_path, existing_files, self.__class__.__name__):
                try:
                    result = self.analyze_image(image_path)
                    self.save_result(image_path, result)
                    processed_images += 1
                    logging.info(f"Processed {processed_images}/{total_images}: {os.path.basename(image_path)}")
                except Exception as e:
                    logging.error(f"Error processing {image_path}: {e}")

        return total_images, processed_images

    def _log_processing_summary(self, total_images: int, processed_images: int, start_time: float) -> None:
        total_time = time.time() - start_time
        logging.info(f"Total processing time: {total_time:.2f} seconds")
        logging.info(f"Processed {processed_images}/{total_images} images")

    def save_result(self, image_path: str, result: Dict) -> None:
        json_path = f"{os.path.splitext(image_path)[0]}_{self.__class__.__name__}.json"
        self.ensure_output_directory(os.path.dirname(json_path))
        with open(json_path, 'w') as f:
            json.dump(result, f, indent=2)
        logging.info(f"Saved results to {json_path}")

    def ensure_output_directory(self, path: str) -> None:
        os.makedirs(path, exist_ok=True)

    def get_image_files(self) -> List[str]:
        image_files = []
        for root, _, files in os.walk(self.directory):
            for file in files:
                if file.lower().endswith(self.image_extensions):
                    image_files.append(os.path.join(root, file))
        return image_files

    def get_existing_json_files(self) -> List[str]:
        return json_utils.get_existing_json_files(self.directory)



###### FILENAME: api_utils.py ######

import logging
import time
import json
import os
from functools import wraps
from typing import Callable, Dict, Any, Optional
import requests

def log_api_conversation(logger: logging.Logger, data: Dict[str, Any], log_conversation: bool):
    if log_conversation:
        logger.debug("API Conversation:")
        logger.debug(json.dumps(data, indent=2))

def retry_with_backoff(max_retries: int = 5, initial_wait: float = 1, backoff_factor: float = 2):
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            retries = 0
            wait_time = initial_wait
            while retries < max_retries:
                try:
                    return func(*args, **kwargs)
                except requests.RequestException as e:
                    if isinstance(e, requests.HTTPError) and e.response.status_code == 500:
                        logging.warning(f"Server error (500). Retrying in {wait_time:.2f} seconds...")
                    else:
                        logging.warning(f"Request failed: {e}. Retrying in {wait_time:.2f} seconds...")
                    time.sleep(wait_time)
                    retries += 1
                    wait_time *= backoff_factor
            raise Exception(f"Failed after {max_retries} retries")
        return wrapper
    return decorator

@retry_with_backoff()
def send_llm_request(data: Dict[str, Any], api_key: str, api_url: str, timeout: float = 30.0) -> Dict[str, Any]:
    llm_logger = logging.getLogger('LLM_API')
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {api_key}"
    }
    try:
        response = requests.post(api_url, json=data, headers=headers, timeout=timeout)
        response.raise_for_status()
        response_data = response.json()
        log_api_conversation(llm_logger, {"request": data, "response": response_data}, True)
        return response_data
    except requests.RequestException as e:
        llm_logger.error(f"Error in LLM API request: {str(e)}")
        llm_logger.error(f"Response content: {e.response.text if e.response else 'No response content'}")
        raise

def safe_api_call(func: Callable[..., Dict[str, Any]]) -> Callable[..., Optional[Dict[str, Any]]]:
    @wraps(func)
    def wrapper(*args: Any, **kwargs: Any) -> Optional[Dict[str, Any]]:
        try:
            return func(*args, **kwargs)
        except requests.RequestException as e:
            logging.error(f"API call failed: {str(e)}")
            return None
    return wrapper


###### FILENAME: clip_analyzer.py ######

import os
import logging
import time
import requests
import json
from typing import Dict, Any, Optional
from analyzer import Analyzer
from api_utils import retry_with_backoff, log_api_conversation
from image_utils import encode_image_to_base64, generate_unique_code
import json_utils

class CLIPAnalyzer(Analyzer):
    def __init__(self, config):
        super().__init__(config.image_directory)
        self.config = config
        self.logger = logging.getLogger('CLIP_API')

    def save_json(self, data: Any, filename: str):
        try:
            with open(filename, 'w') as f:
                json.dump(data, f, indent=4)
            self.logger.info(f"Saved output to {filename}")
        except Exception as e:
            self.logger.error(f"Error saving JSON to {filename}: {str(e)}")

    @retry_with_backoff(max_retries=5, initial_wait=1, backoff_factor=2)
    def send_clip_request(self, image_base64: str, request_type: str, mode: Optional[str] = None) -> Optional[Dict[str, Any]]:
        headers = {"Content-Type": "application/json"}
        payload = {
            "image": image_base64,
            "model": self.config.clip_model_name,
        }
        
        if request_type == "prompt" and mode:
            payload["mode"] = mode

        try:
            # Mask the image content in logs
            log_payload = {**payload, "image": "[BASE64_IMAGE_CONTENT]"}
            self.logger.debug(f"Sending {request_type} request to {self.config.api_base_url}/interrogator/{request_type} with payload: {log_payload}")
            
            response = requests.post(
                f"{self.config.api_base_url}/interrogator/{request_type}",
                json=payload,
                headers=headers,
                timeout=self.config.timeout
            )
            response.raise_for_status()
            response_data = response.json()
            
            # Log the API conversation if enabled
            if self.config.log_api_conversation:
                log_api_conversation(self.logger, {"request": log_payload, "response": response_data}, self.config.log_api_conversation)
            
            return response_data
        except requests.HTTPError as e:
            self.logger.error(f"HTTP error occurred during {request_type}: {e}")
            self.logger.error(f"Response content: {e.response.text if e.response else 'No response content'}")
            return None
        except requests.RequestException as e:
            self.logger.error(f"Error in CLIP API request during {request_type}: {str(e)}")
            return None

    def analyze_image(self, image_path: str) -> Optional[Dict[str, Any]]:
        try:
            image_base64 = encode_image_to_base64(image_path)
            if image_base64 is None:
                self.logger.error(f"Failed to encode image: {image_path}")
                return None
            
            results = self.send_clip_request(image_base64, "analyze")
            if results is None:
                self.logger.error(f"Analysis failed for image: {image_path}")
                return None
            
            return {
                'file_info': self._get_file_info(image_path),
                'analysis': results
            }
        except Exception as e:
            self.logger.error(f"Error analyzing image {image_path}: {str(e)}")
            return None

    def prompt_image(self, image_path: str, mode: str) -> Optional[Dict[str, Any]]:
        try:
            image_base64 = encode_image_to_base64(image_path)
            if image_base64 is None:
                self.logger.error(f"Failed to encode image: {image_path}")
                return None

            results = self.send_clip_request(image_base64, "prompt", mode)
            if results is None:
                self.logger.error(f"Prompt generation failed for image: {image_path} with mode: {mode}")
                return None
            
            return {
                'file_info': self._get_file_info(image_path),
                'prompts': results
            }
        except Exception as e:
            self.logger.error(f"Error prompting image {image_path}: {str(e)}")
            return None

    def _get_file_info(self, image_path: str) -> Dict[str, Any]:
        return {
            'filename': os.path.basename(image_path),
            'unique_hash': generate_unique_code(image_path),
            'date_created': os.path.getctime(image_path),
            'date_processed': time.time(),
            'file_size': os.path.getsize(image_path)
        }

    def process_images(self):
        existing_files = json_utils.get_existing_json_files(self.config.output_directory)
        for image_path in self.get_image_files():
            if json_utils.should_process_file(image_path, existing_files, self.__class__.__name__, self.config):
                if self.config.clip_enabled:
                    result = self.analyze_image(image_path)
                    if result is not None:
                        self.save_result(image_path, result)
                    else:
                        self.logger.warning(f"Skipping JSON creation for {image_path} due to analysis error")
                if self.config.llm_enabled:
                    modes = self.config.selected_prompts
                    for mode in modes:
                        result = self.prompt_image(image_path, mode)
                        if result is not None:
                            self.save_result(image_path, result)
                        else:
                            self.logger.warning(f"Skipping JSON creation for {image_path} due to prompt error")

    def get_image_files(self):
        for root, _, files in os.walk(self.config.image_directory):
            for file in files:
                if file.lower().endswith(tuple(self.config.image_file_extensions)):
                    yield os.path.join(root, file)

    def save_result(self, image_path: str, result: Dict[str, Any]):
        try:
            json_path = f"{os.path.splitext(image_path)[0]}_{self.__class__.__name__}.json"
            with open(json_path, 'w') as f:
                json.dump(result, f, indent=4)
            self.logger.info(f"Saved analysis result to {json_path}")
            
            # Process JSON to TXT if enabled
            json_utils.process_json_to_txt(self.config, result, os.path.dirname(json_path))
        except Exception as e:
            self.logger.error(f"Error saving result to {json_path}: {str(e)}")




###### FILENAME: config.py ######

import os
from dotenv import load_dotenv
from typing import Dict, Any

load_dotenv()

class Config:
    """
    Configuration class for managing application settings.
    Loads settings from environment variables with default values.
    """

    def __init__(self):
        # API Keys
        self.serper_api_key = os.getenv('SERPER_API_KEY')
        self.openai_api_key = os.getenv('OPENAI_API_KEY')
        self.google_api_key = os.getenv('GOOGLE_API_KEY')
        self.google_cse_id = os.getenv('GOOGLE_CSE_ID')
        self.agentops_api_key = os.getenv('AGENTOPS_API_KEY')

        # API Configuration
        self.api_base_url = os.getenv('API_BASE_URL', 'http://localhost:7860')
        self.timeout = int(os.getenv('TIMEOUT', '60'))  # Increase to 60 seconds or more

        # Directory Settings
        self.image_directory = os.getenv('IMAGE_DIRECTORY', 'path_to_images')
        self.output_directory = os.getenv('OUTPUT_DIRECTORY', 'path_to_output')

        # Logging Configuration
        self.logging_level = os.getenv('LOGGING_LEVEL', 'INFO')
        self.logging_format = os.getenv('LOGGING_FORMAT', '%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        self.log_to_console = os.getenv('LOG_TO_CONSOLE', 'True').lower() == 'true'
        self.log_to_file = os.getenv('LOG_TO_FILE', 'True').lower() == 'true'
        self.log_file = os.getenv('LOG_FILE', 'Log.log')
        self.log_mode = 'w'  # Always overwrite log file
        self.log_api_conversation = os.getenv('LOG_API_CONVERSATION', 'False').lower() == 'true'

        # Model Settings
        self.clip_model_name = os.getenv('CLIP_MODEL_NAME', 'ViT-L-14')
        self.caption_types = os.getenv('CAPTION_TYPES', 'caption,best,fast,classic,negative').split(',')

        # LLM Settings
        self.llm_api_base_url = os.getenv('LLM_API_BASE_URL', 'https://api.openai.com/v1/chat/completions')
        self.llm_model = os.getenv('LLM_MODEL', 'gpt-4')
        self.llm_system_content = os.getenv('LLM_SYSTEM_CONTENT', 'Your default system content here')

        # File Handling Settings
        self.create_individual_files = os.getenv('CREATE_INDIVIDUAL_FILES', 'True').lower() == 'true'
        self.create_prompt_list = os.getenv('CREATE_PROMPT_LIST', 'True').lower() == 'true'
        self.create_master_files = os.getenv('CREATE_MASTER_FILES', 'True').lower() == 'true'
        self.list_file_mode = os.getenv('LIST_FILE_MODE', 'w')
        self.master_analysis_filename = os.getenv('MASTER_ANALYSIS_FILENAME', 'master_analysis.json')
        self.process_json_without_images = os.getenv('PROCESS_JSON_WITHOUT_IMAGES', 'False').lower() == 'true'

        # Image File Extensions
        self.image_file_extensions = os.getenv('IMAGE_FILE_EXTENSIONS', '.png,.jpg,.jpeg').split(',')

        # LLM Configurations
        self.llms = self._load_llm_configs()

        # Analysis Control
        self.clip_enabled = os.getenv('ENABLE_CLIP_ANALYSIS', 'True').lower() == 'true'
        self.llm_enabled = os.getenv('ENABLE_LLM_ANALYSIS', 'False').lower() == 'true'
        self.enable_json_processing = os.getenv('ENABLE_JSON_PROCESSING', 'True').lower() == 'true'

        # Retry Configuration
        self.retry_limit = int(os.getenv('RETRY_LIMIT', '5'))
        self.sleep_interval = int(os.getenv('SLEEP_INTERVAL', '5'))

        # LLM Parameters
        self.temperature = float(os.getenv('TEMPERATURE', '0.7'))
        self.max_tokens = int(os.getenv('MAX_TOKENS', '300'))
        self.top_p = float(os.getenv('TOP_P', '1.0'))
        self.frequency_penalty = float(os.getenv('FREQUENCY_PENALTY', '0.0'))
        self.presence_penalty = float(os.getenv('PRESENCE_PENALTY', '0.0'))

        # Selected Prompts
        self.selected_prompts = [p for p in os.getenv('SELECTED_PROMPTS', '').split(',') if p]

        # New Analysis Modes
        self.enable_caption = os.getenv('ENABLE_CAPTION', 'True').lower() == 'true'
        self.enable_best = os.getenv('ENABLE_BEST', 'True').lower() == 'true'
        self.enable_fast = os.getenv('ENABLE_FAST', 'True').lower() == 'true'
        self.enable_classic = os.getenv('ENABLE_CLASSIC', 'True').lower() == 'true'
        self.enable_negative = os.getenv('ENABLE_NEGATIVE', 'True').lower() == 'true'

        # Additional settings
        self.process_json_to_txt = os.getenv('PROCESS_JSON_TO_TXT', 'True').lower() == 'true'

    def _load_llm_configs(self) -> Dict[str, Dict[str, Any]]:
        llms = {}
        for i in range(1, 5):  # Assuming a maximum of 4 LLM configurations
            enabled = os.getenv(f'LLM_{i}_ENABLED', 'False').lower() == 'true'
            if enabled:
                llms[f'LLM_{i}'] = {
                    'api_url': os.getenv(f'LLM_{i}_API_URL'),
                    'api_key': os.getenv(f'LLM_{i}_API_KEY'),
                }
        return llms

    def get_openai_api_key(self) -> str:
        return self.openai_api_key  # Make sure this attribute is set in the __init__ method

    def get_prompt_options(self, prompt_id: str) -> Dict[str, Any]:
        return {
            'PROMPT_TEXT': os.getenv(f'{prompt_id.upper()}_PROMPT_TEXT', 'Default prompt text'),
            'TEMPERATURE': float(os.getenv(f'{prompt_id.upper()}_TEMPERATURE', str(self.temperature))),
            'MAX_TOKENS': int(os.getenv(f'{prompt_id.upper()}_MAX_TOKENS', str(self.max_tokens)))
        }

    def _get_enabled_modes(self):
        return [mode for mode, enabled in {
            'caption': self.enable_caption,
            'best': self.enable_best,
            'fast': self.enable_fast,
            'classic': self.enable_classic,
            'negative': self.enable_negative
        }.items() if enabled]

    def __str__(self) -> str:
        return f"""
        Configuration:
        - API Base URL: {self.api_base_url}
        - Timeout: {self.timeout}
        - Image Directory: {self.image_directory}
        - Output Directory: {self.output_directory}
        - CLIP Model: {self.clip_model_name}
        - CLIP Mode: {self.clip_mode}
        - LLM Model: {self.llm_model}
        - Enable CLIP Analysis: {self.enable_clip_analysis}
        - Enable LLM Analysis: {self.enable_llm_analysis}
        - Enable JSON Processing: {self.enable_json_processing}
        """


###### FILENAME: image_utils.py ######

import base64
import hashlib
import logging
from typing import Optional
import os

def generate_unique_code(image_path: str) -> str:
    """
    Generates a unique MD5 hash for the given image file.

    Args:
        image_path (str): The path to the image file.

    Returns:
        str: The MD5 hash of the image file.
    """
    try:
        with open(image_path, "rb") as f:
            file_hash = hashlib.md5()
            chunk = f.read(8192)
            while chunk:
                file_hash.update(chunk)
                chunk = f.read(8192)
        return file_hash.hexdigest()
    except Exception as e:
        logging.error(f"Error generating unique code for {image_path}: {str(e)}")
        return f"error_{os.path.basename(image_path)}"

def encode_image_to_base64(image_path: str) -> Optional[str]:
    """
    Encodes an image file to a base64 string.

    Args:
        image_path (str): The path to the image file.

    Returns:
        Optional[str]: The base64 encoded string of the image content, or None if an error occurs.
    """
    try:
        # Check if the file exists and is accessible
        if not os.path.exists(image_path):
            logging.error(f"Image file does not exist: {image_path}")
            return None

        # Read the image file in binary mode
        with open(image_path, 'rb') as image_file:
            encoded_string = base64.b64encode(image_file.read()).decode('utf-8')
            logging.info(f"Successfully encoded image to base64: {image_path}")
            return encoded_string
    except Exception as e:
        logging.error(f"Error encoding image to base64 {image_path}: {str(e)}")
        return None

# Keep other existing functions like resize_image


###### FILENAME: json_utils.py ######

import os
import json
import logging
from typing import Dict, Any, List, Set

def save_json(file_path: str, data: Dict[str, Any]) -> None:
    try:
        if os.path.exists(file_path):
            with open(file_path, 'r', encoding='utf-8') as json_file:
                existing_data = json.load(json_file)
            
            # Update file_info
            existing_data['file_info'] = data['file_info']
            
            # Merge analysis results
            for mode, result in data['analysis'].items():
                if mode not in existing_data['analysis']:
                    existing_data['analysis'][mode] = result
                elif result['model'] != existing_data['analysis'][mode]['model']:
                    existing_data['analysis'][f"{mode}_{result['model']}"] = result
            
            data = existing_data
        
        with open(file_path, 'w', encoding='utf-8') as json_file:
            json.dump(data, json_file, ensure_ascii=False, indent=4)
        logging.info(f"JSON output created/updated: {file_path}")
    except IOError as e:
        logging.error(f"Failed to create or write to file: {e}, Path attempted: {file_path}")

def get_existing_json_files(directory: str) -> Set[str]:
    json_files = set()
    for root, _, files in os.walk(directory):
        for file in files:
            if file.lower().endswith('.json'):
                json_files.add(file)
    return json_files

def should_process_file(file_path: str, existing_files: List[str], analyzer_name: str, config) -> bool:
    json_filename = f"{os.path.splitext(os.path.basename(file_path))[0]}_{analyzer_name}.json"
    if json_filename in existing_files:
        json_path = os.path.join(config.output_directory, json_filename)
        if os.path.exists(json_path):
            with open(json_path, 'r') as f:
                existing_data = json.load(f)
            
            # Check if all caption types are already processed
            existing_types = set(existing_data.get('analysis', {}).keys())
            required_types = set(config.caption_types)
            
            if required_types.issubset(existing_types):
                logging.info(f"Skipping {file_path}, all required caption types already processed.")
                return False
    return True

def process_json_to_txt(config, json_data: Dict[str, Any], output_dir: str):
    if not config.process_json_to_txt:
        return
        return
    filename = json_data['file_info']['filename']
    base_name = os.path.splitext(filename)[0]
    base_name = os.path.splitext(filename)[0]
    for mode, content in json_data['analysis'].items():
        if isinstance(content, str):
            txt_filename = f"{base_name}_{mode}.txt"
            txt_path = os.path.join(output_dir, txt_filename)
            with open(txt_path, 'w', encoding='utf-8') as f:
                f.write(content)
            logging.info(f"Created txt file: {txt_path}")

def process_existing_json_files(config):
    logging.info("Processing existing JSON files...")
    json_files = get_existing_json_files(config.image_directory)
    
    for json_file in json_files:
        file_path = os.path.join(config.image_directory, json_file)
        try:
            with open(file_path, 'r') as f:
                data = json.load(f)
            
            # Process the JSON data as needed, but don't create any txt files
            # You can add any necessary processing logic here
            
            logging.info(f"Processed {json_file}")
        except Exception as e:
            logging.error(f"Error processing {json_file}: {str(e)}")
    
    logging.info("Finished processing existing JSON files")


###### FILENAME: logging_setup.py ######

import os
import logging

def setup_logging(config):
    """
    Setup logging configurations based on the configuration values.

    Args:
        config: Configuration object containing logging settings.

    This function sets up file and console logging, as well as specific loggers for API communication, CLIP API, and LLM API.
    """
    log_file = os.path.join(config.output_directory, 'analysis.log')
    os.makedirs(config.output_directory, exist_ok=True)

    # Create a custom logger
    logger = logging.getLogger()
    logger.setLevel(config.logging_level.upper())  # Use the logging level from config

    # Create handlers
    handlers = []
    if config.log_to_file:
        f_handler = logging.FileHandler(log_file, mode='a', encoding='utf-8')
        f_handler.setLevel(logging.DEBUG)
        handlers.append(f_handler)
    if config.log_to_console:
        c_handler = logging.StreamHandler()
        c_handler.setLevel(logging.INFO)
        handlers.append(c_handler)

    # Create a consistent formatter with short time format
    formatter = logging.Formatter(
        fmt='%(asctime)s - %(levelname)s - %(name)s - %(message)s',
        datefmt='%H:%M:%S'
    )

    for handler in handlers:
        handler.setFormatter(formatter)
        logger.addHandler(handler)

    # Suppress logging from PIL and other noisy libraries
    logging.getLogger('PIL').setLevel(logging.WARNING)
    logging.getLogger('urllib3').setLevel(logging.WARNING)  # Suppress urllib3 DEBUG logs

    # Setup API logging
    if config.log_to_file:
        api_logger = logging.getLogger('API')
        api_logger.setLevel(logging.DEBUG)
        api_handler = logging.FileHandler(os.path.join(config.output_directory, 'api_communication.log'), mode='w', encoding='utf-8')
        api_handler.setFormatter(formatter)
        api_logger.addHandler(api_handler)

        # Setup CLIP API logger
        clip_logger = logging.getLogger('CLIP_API')
        clip_logger.setLevel(logging.DEBUG)
        clip_handler = logging.FileHandler(os.path.join(config.output_directory, 'api_clip.log'), mode='w', encoding='utf-8')
        clip_handler.setFormatter(formatter)
        clip_logger.addHandler(clip_handler)

        # Setup LLM API logger if needed
        llm_logger = logging.getLogger('LLM_API')
        llm_logger.setLevel(logging.DEBUG)
        llm_handler = logging.FileHandler(os.path.join(config.output_directory, 'api_llm.log'), mode='w', encoding='utf-8')
        llm_handler.setFormatter(formatter)
        llm_logger.addHandler(llm_handler)



###### FILENAME: TEST.py ######

import requests  # Import the requests library to make HTTP requests
import base64  # Import base64 for encoding images
import os  # Import os for file path operations
import json  # Import json for handling JSON data

def encode_image_to_base64(image_path: str) -> str:
    """
    Encodes an image file to a base64 string.

    Args:
        image_path (str): The path to the image file.

    Returns:
        str: The base64 encoded string of the image.
    """
    with open(image_path, "rb") as image_file:  # Open the image file in binary read mode
        return base64.b64encode(image_file.read()).decode('utf-8')  # Encode the image and decode to UTF-8 string

def save_json(data, filename: str):
    """
    Saves data to a JSON file.

    Args:
        data: The data to save (usually a dictionary).
        filename (str): The name of the file to save the data to.
    """
    with open(filename, 'w') as f:  # Open the file in write mode
        json.dump(data, f, indent=4)  # Write the data to the file in JSON format with indentation
    print(f"Saved output to {filename}")  # Print confirmation of save

def analyze_image(image_path: str, api_base_url: str, model: str, timeout: int = 60):
    """
    Sends an image to the CLIP API for analysis.

    Args:
        image_path (str): The path to the image file.
        api_base_url (str): The base URL of the API.
        model (str): The model name to use for analysis.
        timeout (int): The timeout for the API request (default is 60 seconds).

    Returns:
        dict: The JSON response from the API containing analysis results.
    """
    image_base64 = encode_image_to_base64(image_path)  # Encode the image to base64
    
    # Prepare the payload for the API request
    payload = {
        "image": image_base64,  # The base64 encoded image
        "model": model  # The model to use for analysis
    }
    
    headers = {"Content-Type": "application/json"}  # Set the content type to JSON
    
    # Make a POST request to the API for analysis
    response = requests.post(
        f"{api_base_url}/interrogator/analyze",  # API endpoint for analysis
        json=payload,  # The payload containing the image and model
        headers=headers,  # The headers for the request
        timeout=timeout  # Timeout for the request
    )
    response.raise_for_status()  # Raise an error for bad responses (4xx or 5xx)
    return response.json()  # Return the JSON response from the API

def prompt_image(image_path: str, api_base_url: str, model: str, mode: str, timeout: int = 60):
    """
    Sends an image to the CLIP API to generate a prompt.

    Args:
        image_path (str): The path to the image file.
        api_base_url (str): The base URL of the API.
        model (str): The model name to use for generating prompts.
        mode (str): The mode for prompt generation (e.g., 'fast', 'best').
        timeout (int): The timeout for the API request (default is 60 seconds).

    Returns:
        dict: The JSON response from the API containing prompt results.
    """
    image_base64 = encode_image_to_base64(image_path)  # Encode the image to base64
    
    # Prepare the payload for the API request
    payload = {
        "image": image_base64,  # The base64 encoded image
        "model": model,  # The model to use for generating prompts
        "mode": mode  # The mode for prompt generation
    }
    
    headers = {"Content-Type": "application/json"}  # Set the content type to JSON
    
    # Make a POST request to the API for prompt generation
    response = requests.post(
        f"{api_base_url}/interrogator/prompt",  # API endpoint for prompt generation
        json=payload,  # The payload containing the image, model, and mode
        headers=headers,  # The headers for the request
        timeout=timeout  # Timeout for the request
    )
    response.raise_for_status()  # Raise an error for bad responses (4xx or 5xx)
    return response.json()  # Return the JSON response from the API

def main():
    # Configuration
    api_base_url = "http://localhost:7860"  # Change if your API runs on a different URL
    model = "ViT-L-14"  # Change to the model you are using
    mode = "fast"  # Mode for prompt; can be 'fast', 'best', 'classic', 'negative', 'caption'
    image_filename = "test.png"  # Replace with your image filename
    
    # Check if image exists
    if not os.path.isfile(image_filename):  # Verify that the image file exists
        print(f"Image file {image_filename} not found in the current directory.")
        return
    
    # Analyze the image
    try:
        analysis_result = analyze_image(image_filename, api_base_url, model)
        save_json(analysis_result, "analyze_output.json")
    except Exception as e:
        print(f"An error occurred during analysis: {e}")
    
    # Generate prompt from the image
    try:
        prompt_result = prompt_image(image_filename, api_base_url, model, mode)
        save_json(prompt_result, "prompt_output.json")
    except Exception as e:
        print(f"An error occurred during prompt generation: {e}")

if __name__ == "__main__":
    main()


###### FILENAME: utils.py ######

import base64
import hashlib
import requests
import os
import logging
from functools import wraps
from PIL import Image
import io
from typing import Optional, Dict, Any, Callable

def safe_api_call(func: Callable) -> Callable:
    """
    Decorator to safely handle API calls and log errors.
    """
    @wraps(func)
    def wrapper(*args, **kwargs):
        try:
            return func(*args, **kwargs)
        except requests.RequestException as e:
            logging.error(f"API request failed: {str(e)}")
            return {"error": str(e)}
        except Exception as e:
            logging.exception(f"Unexpected error in API call: {str(e)}")
            return {"error": "An unexpected error occurred"}
    return wrapper

def validate_directory(directory: str) -> None:
    """
    Validate if a directory exists and is accessible.
    """
    if not os.path.isdir(directory):
        raise ValueError(f"The specified path is not a valid directory: {directory}")
    if not os.access(directory, os.R_OK):
        raise PermissionError(f"You don't have read permissions for the directory: {directory}")


