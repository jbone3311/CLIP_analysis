## Directory Structure ##
./
    .env
    .gitignore
    analysis_main.py
    analyzer.py
    api_utils.py
    Before Refactor (OLD CODE).zip
    clip_analyzer.py
    CodeSheetConfig.ini
    Code_From_CWD.txt
    config.py
    Dir_Structure.txt
    image_utils.py
    Info.txt
    json_utils.py
    llm_analyzer.py
    LLM_CodeSheetV2.exe
    logging_setup.py
    README.md
    test.png
    TEST.py
    utils.py
    .git/
        COMMIT_EDITMSG
        config
        description
        FETCH_HEAD
        HEAD
        index
        ORIG_HEAD
        hooks/
            applypatch-msg.sample
            commit-msg.sample
            fsmonitor-watchman.sample
            post-update.sample
            pre-applypatch.sample
            pre-commit.sample
            pre-merge-commit.sample
            pre-push.sample
            pre-rebase.sample
            pre-receive.sample
            prepare-commit-msg.sample
            push-to-checkout.sample
            update.sample
        info/
            exclude
        logs/
            HEAD
            refs/
                heads/
                    main
                remotes/
                    origin/
                        main
        objects/
            00/
                d1f703ed65a512edaa66502a788801006f11d4
            01/
                363af75eef02ef1dfe65d39d7dc2927ec113b8
            04/
                c9e599e36b7f2ced28a31af4a36b88b9b1bff3
            05/
                858c7d0808f3d64570a77f8aca34823fe02421
            06/
                f0cfda7d8b1490d0602d0a251ba23ddd083e1a
                f62320db2a1952d218ef234b563eb22522f09d
            09/
                b55fca364bc89b6bda729320fe45e2e4a61f5e
            0a/
                7ac1a4e73c95918a4f207740529fad15bd6f79
            10/
                5dbceb4f9ea2e2cc11e2d0bd06cea2954b4f0e
            11/
                0ca06e42e4d77e52122b762f20c3b5c74847c8
            12/
                2d2a82ce9f57349263c2f1d912401b34afbb6f
            14/
                143012ca8153a65b874692a7593376d731ea99
                a0be5e43b999d23e0afc2b63a48509e5c03698
            15/
                38383cb4d5ab9b549742274fd7b5842f8d96be
            17/
                1c35e99f5fabe2d12bf39568f56ef5e4bda197
            19/
                7f42d48dbe921a275f108f85233d16d5c66462
            1a/
                62411753d4eb1b19712bffd299a390c08121e4
            1b/
                46ca506b3812182d9e11e97555226ee8c3d608
                57956dbad23f674846e8b4fb07e6c65dafe321
                78c71243e361a5122527e13e7731f566781ce5
            20/
                8fdd5f53a04175ce4eeca994ff0a0373654475
            21/
                8087db7dc42d4b59095e693f098aa95afca11e
            23/
                12dfd9e73360e76dafa950adf8b411338fe109
            28/
                1d703ca8a5e6418ab67f938ae8057f971bf80d
            2a/
                cc6e4ed4d6f4d7f288927a6ccdd401279e7772
            2c/
                edc9273b09e8e813e7d478cfcbd1a8ac965a9c
                fd812683bb4fdf6001036cd2e00a094d8ecbce
            2e/
                a313fbd02d944d30b438b31f80bc4e1dc2db80
                b037b49e9a5830d449588525ba62f54a8d4372
                fe36e980b21d7aa98fb5a27d9d53893a7da829
            2f/
                0f77ac982253b588dc76aafc91f519fdb729d3
                85059977ee9d5233b15cb94ea0c4a29816e365
            32/
                62d8691b43dbf277aed243f0cd778340dc29ca
            33/
                29cc6a54226af9ec4b353625d22853bcd36ba2
                5a859abbddcf85ddcc458b7f3b7db482838cf4
            34/
                6d5544a94821b6db80a232d0ae73287ce828b7
            38/
                985789b4be37afb3546c4729a20a6ac9de3a1b
            3a/
                0f13e0500d93ae06abecdf94050e2d6af326b4
            3b/
                104d6b2a1f8eb2df76cae16e0e0d2091e63a12
            3c/
                da5ea0c5fc4b06b99414f0faeb6df98c530c96
            3f/
                2c76c4b88c79d6df4de57c222b671bc4acdd34
            41/
                384258cd3593f174e6af4c3323b3b0b6b501b7
                f1921a29240ed1564acec36df3cf39716e2476
            42/
                ddc18de1559f43c55209177e90e32348e9eac4
            43/
                1a30a922f1ef2c666f42e8fe7b9ca3504cb1f3
                b81a09f33338aee0ea83abe9d90c3e700d116f
            44/
                27e5315e9b6138c2aabe66b2b7ee161b977c8b
                2c4d96779eb6d34c940211adcc09df34bb7316
                ae09b40013728d0071e07ed89b660dd14cbd0c
            46/
                accc6aed2be2b2c358fbfd3d9846a45e42e15b
            48/
                5442c29d4a13e963f0e1e2e9482bb5af519d3e
            4a/
                9a2d86738ed2a39105a3788850ef385aa640a7
                ed745baa7e38a63bb7302b5f640855cde8e679
            4b/
                14f6ceaf1225250abff5fdb7aea8d89e2ecaf9
            4c/
                05e6aa8483cd23c67c2397bf8a59eb4809ec95
                cfe63fe69ceca170be867ad14d31f736231797
            4e/
                74bcde14be10fed65ed87d21cc920519e19edc
                86f0211bbc4e2e5e6a9f6afb2c49fef903d894
                9effc7b30be4839161c70452622a11e443e96c
            51/
                0adb0c4449adacdc6c45773510aa1ff9b3589b
                d1d770fff8a73b002e5e3e215755aaf1bdbe1a
            52/
                694e94af0c0105262746eeb9181a660eeed06c
            53/
                77a3dd45c706f304d0d2499685ceae792c492d
            54/
                a83c5cc6112abb8e0ee6a85dc3f4d5c4228415
            55/
                502ad96551fea27292a1205fb34b97760a0c0d
            56/
                5030af84d2c8ab2949905806a6c99dd0776446
                f880e2a49b1647a160ee5e8819d914567abf60
            57/
                904a1fc9edeb43977fd1bb07bdd607f3441c93
            5a/
                78e63225f64f6875a303048540a3ef790e2d34
                ac8448b1fa20361f792198006ca2a0212a2f25
            5b/
                ab203d7fd24bb58540da9e8c610f7f54003200
            5f/
                adfa6d90e9bc9741cdd40755773d957a245095
            61/
                5bb3be1143988082690293e03c5b36e6747a58
            63/
                d63d0fc603bb461288c724a28f00b70c49b4ec
            65/
                716bf88866d42cb1f5cef4c514887d19445afb
            66/
                eed65d9f2ed8ed53f49e626461493a48f6313c
            67/
                b5577a351307a2e9b975c5734b135437e9db54
            68/
                725b81f7ad363fc274f4b002eba39ac5953901
            69/
                c8d00bcf98864c3c91e4a3296ec0d6b386b0a9
                dc7b841248c3c73ca0fc890d9de37e1a44cdaa
            6b/
                769b87c40351060454e1b84a9daa5cdb524aad
                c36623b07e74449ac34659003c661d6a4dfb1a
            6d/
                18c9c2c08f8cbd79e8c352d0e2973a22427679
                45e7981c7d25399e5a276ae2a3d72c369ff9a7
            6e/
                01edc16812a6ea645c80ead68687281e83f77d
            70/
                3d65a3bb61c4f017136bd9a9bac25bba05dba9
            71/
                62c335a318aed858d7779f04a01790f964921b
            72/
                70cc991c88a7347b64e3ec42a84a9734ad6259
                e4833b738a5572dbedad149277f07720e5a50e
            73/
                15aab94c64699b12a627f26dacb02f8c9c0d78
            75/
                51de04ed3eba2c8544e06b4b0d38fce0b9674e
            78/
                a222d0efa3298d595a599855100f15a2d6db43
            7b/
                50f2ae5e7f7211dc1f6949e6312f11512989aa
            7d/
                1c6434bb60de5226147d616ef01015e76000f0
            7e/
                55972ad34b1dd3bdbc8cf86d0843a477693bb4
                8c35f7895bbf25ce2ee4261ec452edbb208f03
            80/
                ce59828d7a25f49d11904781121bd47517b323
            81/
                34429f5efbc0ed84cbf64affa2cf35a34bdd25
            83/
                3543101dbaae482f79d04f022be1faeca1a3a3
            84/
                078c4469f2b1670f2e6a6a6ad2fd292484a161
            85/
                33268ec2390c8eeae927d4dabc425f81aa35c6
                f7b1098fbd59ed03a3881be001556d46fc845e
            87/
                60912767c664e8f900950f3c2d331a6476adbb
            8a/
                428ed09dbdd3da9e3e27f1f1cd091d31c405cd
            8b/
                a4bd4f7da2fbf6cb2a4e0d0f41f9125888e15a
            8e/
                51200d0afc7bb0a5ef144342941835a007ea23
            90/
                c5250571b418089881d0b370cb55a907b017f4
                e84a4dffe271af2d9148f99d0418dedc9af356
            91/
                935678916e0f61138543914e188a355a904266
            92/
                cf921f497e678e14658c4c7de4a81e28df60e6
            96/
                3119b18d3e674dc39dd50cd947766f8804175a
                95b74168640e69e1d274691349cd936f627984
            97/
                149e0b7f0469fbc9779b9cce95d01cf7a5936d
                40c423c2b951eef1018023699fad291c680400
                9688056d0242ac45154065bdab70483d1d7099
            98/
                1b97272287ef06f7cbd808f559a9b39add68ad
            9a/
                c7c4daf231acb6017e5665dc60f32218cd2851
            9b/
                6cec43bcc4c94c51d1e955baf6a3dd44378bd0
            9c/
                db5cf19b5cf482f2d42c36b834006ef1c2958d
            9d/
                746a318e38dac971deb5009d8512325d1da827
            a0/
                3fa8673995438b9224ef5b6304da6d775a8adf
            a1/
                8178521adb7ecce93bbb082ea4f395d65b3a9d
            a3/
                027d680fb49487f69498a9c66d1bb9efdb0237
            a4/
                5b147aff201a09ee8e9d2d13b10bfcb8b2e8ff
                9e8c9c8c016779b4575d426c8fd16eb865c8ab
            a7/
                1511e577aba3df3db583474232e2c5889bc739
                ace3e8665fe8f03447cb7cf5d724e9f86e374a
                db5c341cae337b13d55a0c0bb12d0e8efb1d46
            aa/
                658af92755e48a2fbdb812f4190715a2a77cf0
            ac/
                ec98edd4b0631ae63d7edb6f8734aaa39f563e
            ad/
                30723467ad488ee00ac303a7ec9320c5fe1efd
                67d44dc5247004866e1d24e8f9b08e4416dbbc
                b7e5d4e5c042d57d92efc7af0bb20a4fc96400
                f90431bdf5e7d1e30777331c7cc97886889172
            ae/
                ab11aae483224397c149b7475b70d138065749
                ba0cf0a3eec7eea9ab7772ffe930d2ca397510
            af/
                34c0b5a9696a6c974eb00da64c9180a776be28
            b0/
                370f431754ff6a2edc5740791cd1e57fce1f96
            b1/
                106780ffbbf9555e07f3c2897fd5cf666b5184
                23e9eafb63e1e877662a6901e188748f1b4741
            b2/
                2d20743c0b25f7566f05852a7e9d637f645f7f
                5719bebf12cbe95293eb2eb6bca6f931a2fdec
                f60574e41d7d2978e9cdd927c23cc1ec8e5ba7
            b3/
                84f7fb77024b52f25c6ad199cf21c13c88e8a5
            b4/
                fc0b239360654a3a8648c9ccde04146861d5e0
            b5/
                8088ca3135ea3e2f7d4b02ee2265545c46b989
            b8/
                4c0c4337f120d22493446a26fd784f6b850d7d
                ad5967c8bdec65edc17f0b58ec8ac27f3262d3
            bb/
                542e24557ff8f99a31532d7d3e8489886093d0
            bc/
                fa9923e522703fea3e83c4483b1f345ae6dfab
            bd/
                f97c1eae29597d19e85db9e9e8a77a02fc45fe
            be/
                683c86f5317a1ee8214a8e95e23f852a242cf6
                f32062e09c49f873a63891a685e302572e475d
            bf/
                72aca796a9db2c5e0985c287d273deb9268c8f
            c1/
                3ed53a153e9d2023db56af9fe8d12b9a717d89
                e0435a7842299b1234dfed5764ab273502b3b9
            c2/
                4eaeaff48e0ebdc13ffbca84dd7e132fedc7d5
                f9d504ac572b3d45b96b031e585bf14991da22
            c5/
                aab2196d73c5947a78a3747f760c55c4b818cb
            c6/
                a4695b849273244563318679a53bf779a2d02b
                b5f3dceaec9e009841aedca32685ee0b8e5f85
            c8/
                7cd4553b546b5196a662fcc0f3bf80d8cf907f
                aa4adfc63f6bc81f26bde89d9d7b6e21eec76b
            c9/
                48b53fa029eb204d6f2970e3bddadf680ae8f8
            ca/
                26d08467178daef794f2ba1f2b5bad6e003db0
                4bbc13a7698526ed65bac1e5f89a00d5c0ed27
            cb/
                42f58cff2c6baec69c9321b5c07a0642158a2a
            cc/
                5a3e94aab3fe6c863db25169cdce6911ea166e
            cf/
                9f31dfd6de924a0bfe4616b9eeba53b8abd9ae
            d3/
                fba730d874eff953bdc1e742c2d8fc1b46a3e1
            d4/
                8ecf06614c250592352cf7a48f84ae2aa11b91
            d6/
                ef30e2314f2251d3c873ae82703ec1823e4e78
                f9ac1143e5a83fb9098f1c9d9962b4a4ff58a3
            dc/
                cdfff6a508dced40da8f154dc86d45b09d1ba9
                e8c2758e73889730abc761bb36ce1e349ebcb6
            de/
                06f27cf0925950ed2c0d31e3f75d17aaf29a6e
            df/
                ff068b1634dd3ab77befb0ab3bc80f1ac44386
            e4/
                a07393b7876f6bfd0a4566551f1be18f61f5cd
            e6/
                ac88c99108d0a3c782c62f4ca1782ccdf90e44
                f53c5789c536767397f11de18cb4135fe9712c
            e7/
                149f6a5e0642d4a0feb1d2b19e240e898bac91
            e9/
                c598f088daf091434a18a9d40b8d850a17a979
            ea/
                26810b53e5cc2f06b7ba0ed4e00090f669748a
            eb/
                2519db0f8902504097140f8158ce293c2e9110
            ec/
                cf94bbb9e32d164fda7f37cf066bc5c7c68dc3
                e5edab650abc7f8644c76cb807251ba0ec8512
            ed/
                622d6f6c5b5c3cbd39a7fbbf9c92d0e9eaad27
                7a416949d6e9e2210f9b6b0ce80567b88ebdf1
            ee/
                87a46978f18fdb25851e35f51c6b0a81e82827
            ef/
                6bce238e104eb332cf32412035c0d075aba6a0
            f0/
                806596afc054a21f4d41303b3be69969c54dbf
            f2/
                654353c1fc0e2f13dbf7511e38c2cbe425a2cc
            f3/
                03345aab6ab56c019888d5fe3589440af8bbaf
            f4/
                36b0b3a7402b6495e713ceba9d54df02d71262
            f7/
                0003326dacac408227f6f763c2464a122d61c3
                b494fbdf6fdfd3a858c31774d5a950ac88128a
                c9ff214039b361b36b444292bd03950750fcb9
                f58c77405e25b3061c8ed0bcccff1c96eb4847
            f8/
                eaa8a3848d53bf6b2337c92aafc684912cb49d
            fb/
                60d4b3b1ffe94e3056b9ae7d827709aeb7bd5d
            ff/
                2668437496ced2701b56bf8cd2992c76575fef
                362cbcbd5616d12a6f2dcd4349713b66590e0a
            info/
            pack/
        refs/
            heads/
                main
            remotes/
                origin/
                    main
            tags/
    Images/
        Group/
            Group (1).png
            Group (2).png
            Group (3).png
            Group (4).png
            Group (5).png
            Group (6).png
            Group (7).png
    Output/
        analysis.log
        api_clip.log
        api_communication.log
        api_llm.log

## Main Directory ##

###### FILENAME: analysis_main.py ######

import logging
from config import Config
from clip_analyzer import CLIPAnalyzer
from llm_analyzer import LLMAnalyzer
from logging_setup import setup_logging

def main():
    config = Config()
    setup_logging(config)

    logging.info("### Processing New Batch ###")

    if config.clip_enabled:
        logging.info("Running CLIP Analyzer...")
        clip_analyzer = CLIPAnalyzer(config)
        clip_analyzer.process_images()

    if config.llm_enabled:
        logging.info("Running LLM Analyzer...")
        llm_analyzer = LLMAnalyzer(config)
        llm_analyzer.process_images()

    logging.info("Finished processing")

if __name__ == "__main__":
    main()


###### FILENAME: analyzer.py ######

import os
import json
import logging
import time
from abc import ABC, abstractmethod
from typing import Dict, List, Tuple
from image_utils import generate_unique_code
import json_utils

class Analyzer(ABC):
    def __init__(self, directory: str):
        self.directory = directory
        self.image_extensions: Tuple[str, ...] = ('.jpg', '.jpeg', '.png')

    @abstractmethod
    def analyze_image(self, image_path: str) -> Dict:
        pass

    def process_directory(self) -> None:
        start_time = time.time()
        existing_files = self.get_existing_json_files()

        total_images, processed_images = self._process_images(existing_files)

        self._log_processing_summary(total_images, processed_images, start_time)

    def _process_images(self, existing_files: List[str]) -> Tuple[int, int]:
        total_images, processed_images = 0, 0

        for image_path in self.get_image_files():
            total_images += 1
            if json_utils.should_process_file(image_path, existing_files, self.__class__.__name__):
                try:
                    result = self.analyze_image(image_path)
                    self.save_result(image_path, result)
                    processed_images += 1
                    logging.info(f"Processed {processed_images}/{total_images}: {os.path.basename(image_path)}")
                except Exception as e:
                    logging.error(f"Error processing {image_path}: {e}")

        return total_images, processed_images

    def _log_processing_summary(self, total_images: int, processed_images: int, start_time: float) -> None:
        total_time = time.time() - start_time
        logging.info(f"Total processing time: {total_time:.2f} seconds")
        logging.info(f"Processed {processed_images}/{total_images} images")

    def save_result(self, image_path: str, result: Dict) -> None:
        json_path = f"{os.path.splitext(image_path)[0]}_{self.__class__.__name__}.json"
        self.ensure_output_directory(os.path.dirname(json_path))
        with open(json_path, 'w') as f:
            json.dump(result, f, indent=2)
        logging.info(f"Saved results to {json_path}")

    def ensure_output_directory(self, path: str) -> None:
        os.makedirs(path, exist_ok=True)

    def get_image_files(self) -> List[str]:
        image_files = []
        for root, _, files in os.walk(self.directory):
            for file in files:
                if file.lower().endswith(self.image_extensions):
                    image_files.append(os.path.join(root, file))
        return image_files

    def get_existing_json_files(self) -> List[str]:
        return json_utils.get_existing_json_files(self.directory)



###### FILENAME: api_utils.py ######

import logging
import time
import json
import os
from functools import wraps
from typing import Callable, Dict, Any, Optional
import requests

def log_api_conversation(logger: logging.Logger, data: Dict[str, Any], log_conversation: bool):
    if log_conversation:
        logger.debug("API Conversation:")
        logger.debug(json.dumps(data, indent=2))

def retry_with_backoff(max_retries: int = 5, initial_wait: float = 1, backoff_factor: float = 2):
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            retries = 0
            wait_time = initial_wait
            while retries < max_retries:
                try:
                    return func(*args, **kwargs)
                except requests.RequestException as e:
                    if isinstance(e, requests.HTTPError) and e.response.status_code == 500:
                        logging.warning(f"Server error (500). Retrying in {wait_time:.2f} seconds...")
                    else:
                        logging.warning(f"Request failed: {e}. Retrying in {wait_time:.2f} seconds...")
                    time.sleep(wait_time)
                    retries += 1
                    wait_time *= backoff_factor
            raise Exception(f"Failed after {max_retries} retries")
        return wrapper
    return decorator

@retry_with_backoff()
def send_llm_request(data: Dict[str, Any], api_key: str, api_url: str, timeout: float = 30.0) -> Dict[str, Any]:
    llm_logger = logging.getLogger('LLM_API')
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {api_key}"
    }
    try:
        response = requests.post(api_url, json=data, headers=headers, timeout=timeout)
        response.raise_for_status()
        response_data = response.json()
        log_api_conversation(llm_logger, {"request": data, "response": response_data}, True)
        return response_data
    except requests.RequestException as e:
        llm_logger.error(f"Error in LLM API request: {str(e)}")
        llm_logger.error(f"Response content: {e.response.text if e.response else 'No response content'}")
        raise

def safe_api_call(func: Callable[..., Dict[str, Any]]) -> Callable[..., Optional[Dict[str, Any]]]:
    @wraps(func)
    def wrapper(*args: Any, **kwargs: Any) -> Optional[Dict[str, Any]]:
        try:
            return func(*args, **kwargs)
        except requests.RequestException as e:
            logging.error(f"API call failed: {str(e)}")
            return None
    return wrapper


###### FILENAME: clip_analyzer.py ######

import os
import logging
import time
import requests
import json
from typing import Dict, Any, Optional
from analyzer import Analyzer
from api_utils import retry_with_backoff, log_api_conversation
from image_utils import encode_image_to_base64, generate_unique_code
import json_utils

class CLIPAnalyzer(Analyzer):
    def __init__(self, config):
        super().__init__(config.image_directory)
        self.config = config
        self.logger = logging.getLogger('CLIP_API')

    def save_json(self, data: Any, filename: str):
        try:
            with open(filename, 'w') as f:
                json.dump(data, f, indent=4)
            self.logger.info(f"Saved output to {filename}")
        except Exception as e:
            self.logger.error(f"Error saving JSON to {filename}: {str(e)}")

    @retry_with_backoff(max_retries=5, initial_wait=1, backoff_factor=2)
    def send_clip_request(self, image_base64: str, request_type: str, mode: Optional[str] = None) -> Optional[Dict[str, Any]]:
        headers = {"Content-Type": "application/json"}
        payload = {
            "image": image_base64,
            "model": self.config.clip_model_name,
        }
        
        if request_type == "prompt" and mode:
            payload["mode"] = mode

        try:
            # Mask the image content in logs
            log_payload = {**payload, "image": "[BASE64_IMAGE_CONTENT]"}
            self.logger.debug(f"Sending {request_type} request to {self.config.api_base_url}/interrogator/{request_type} with payload: {log_payload}")
            
            response = requests.post(
                f"{self.config.api_base_url}/interrogator/{request_type}",
                json=payload,
                headers=headers,
                timeout=self.config.timeout
            )
            response.raise_for_status()
            response_data = response.json()
            
            # Log the API conversation if enabled
            if self.config.log_api_conversation:
                log_api_conversation(self.logger, {"request": log_payload, "response": response_data}, self.config.log_api_conversation)
            
            return response_data
        except requests.HTTPError as e:
            self.logger.error(f"HTTP error occurred during {request_type}: {e}")
            self.logger.error(f"Response content: {e.response.text if e.response else 'No response content'}")
            return None
        except requests.RequestException as e:
            self.logger.error(f"Error in CLIP API request during {request_type}: {str(e)}")
            return None

    def analyze_image(self, image_path: str) -> Optional[Dict[str, Any]]:
        try:
            image_base64 = encode_image_to_base64(image_path)
            if image_base64 is None:
                self.logger.error(f"Failed to encode image: {image_path}")
                return None
            
            results = self.send_clip_request(image_base64, "analyze")
            if results is None:
                self.logger.error(f"Analysis failed for image: {image_path}")
                return None
            
            return {
                'file_info': self._get_file_info(image_path),
                'analysis': results
            }
        except Exception as e:
            self.logger.error(f"Error analyzing image {image_path}: {str(e)}")
            return None

    def prompt_image(self, image_path: str, mode: str) -> Optional[Dict[str, Any]]:
        try:
            image_base64 = encode_image_to_base64(image_path)
            if image_base64 is None:
                self.logger.error(f"Failed to encode image: {image_path}")
                return None

            results = self.send_clip_request(image_base64, "prompt", mode)
            if results is None:
                self.logger.error(f"Prompt generation failed for image: {image_path} with mode: {mode}")
                return None
            
            return {
                'file_info': self._get_file_info(image_path),
                'prompts': results
            }
        except Exception as e:
            self.logger.error(f"Error prompting image {image_path}: {str(e)}")
            return None

    def _get_file_info(self, image_path: str) -> Dict[str, Any]:
        return {
            'filename': os.path.basename(image_path),
            'unique_hash': generate_unique_code(image_path),
            'date_created': os.path.getctime(image_path),
            'date_processed': time.time(),
            'file_size': os.path.getsize(image_path)
        }

    def process_images(self):
        existing_files = json_utils.get_existing_json_files(self.config.output_directory)
        for image_path in self.get_image_files():
            if json_utils.should_process_file(image_path, existing_files, self.__class__.__name__, self.config):
                if self.config.clip_enabled:
                    result = self.analyze_image(image_path)
                    if result is not None:
                        self.save_result(image_path, result)
                    else:
                        self.logger.warning(f"Skipping JSON creation for {image_path} due to analysis error")
                if self.config.llm_enabled:
                    modes = self.config.selected_prompts
                    for mode in modes:
                        result = self.prompt_image(image_path, mode)
                        if result is not None:
                            self.save_result(image_path, result)
                        else:
                            self.logger.warning(f"Skipping JSON creation for {image_path} due to prompt error")

    def get_image_files(self):
        for root, _, files in os.walk(self.config.image_directory):
            for file in files:
                if file.lower().endswith(tuple(self.config.image_file_extensions)):
                    yield os.path.join(root, file)

    def save_result(self, image_path: str, result: Dict[str, Any]):
        try:
            json_path = f"{os.path.splitext(image_path)[0]}_{self.__class__.__name__}.json"
            with open(json_path, 'w') as f:
                json.dump(result, f, indent=4)
            self.logger.info(f"Saved analysis result to {json_path}")
            
            # Process JSON to TXT if enabled
            json_utils.process_json_to_txt(self.config, result, os.path.dirname(json_path))
        except Exception as e:
            self.logger.error(f"Error saving result to {json_path}: {str(e)}")




###### FILENAME: config.py ######

import os
from dotenv import load_dotenv
from typing import Dict, Any

load_dotenv()

class Config:
    """
    Configuration class for managing application settings.
    Loads settings from environment variables with default values.
    """

    def __init__(self):
        # API Keys
        self.serper_api_key = os.getenv('SERPER_API_KEY')
        self.openai_api_key = os.getenv('OPENAI_API_KEY')
        self.google_api_key = os.getenv('GOOGLE_API_KEY')
        self.google_cse_id = os.getenv('GOOGLE_CSE_ID')
        self.agentops_api_key = os.getenv('AGENTOPS_API_KEY')

        # API Configuration
        self.api_base_url = os.getenv('API_BASE_URL', 'http://localhost:7860')
        self.timeout = int(os.getenv('TIMEOUT', '60'))  # Increase to 60 seconds or more

        # Directory Settings
        self.image_directory = os.getenv('IMAGE_DIRECTORY', 'path_to_images')
        self.output_directory = os.getenv('OUTPUT_DIRECTORY', 'path_to_output')

        # Logging Configuration
        self.logging_level = os.getenv('LOGGING_LEVEL', 'INFO')
        self.logging_format = os.getenv('LOGGING_FORMAT', '%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        self.log_to_console = os.getenv('LOG_TO_CONSOLE', 'True').lower() == 'true'
        self.log_to_file = os.getenv('LOG_TO_FILE', 'True').lower() == 'true'
        self.log_file = os.getenv('LOG_FILE', 'Log.log')
        self.log_mode = 'w'  # Always overwrite log file
        self.log_api_conversation = os.getenv('LOG_API_CONVERSATION', 'False').lower() == 'true'

        # Model Settings
        self.clip_model_name = os.getenv('CLIP_MODEL_NAME', 'ViT-L-14')
        self.caption_types = os.getenv('CAPTION_TYPES', 'caption,best,fast,classic,negative').split(',')

        # LLM Settings
        self.llm_api_base_url = os.getenv('LLM_API_BASE_URL', 'https://api.openai.com/v1/chat/completions')
        self.llm_model = os.getenv('LLM_MODEL', 'gpt-4')
        self.llm_system_content = os.getenv('LLM_SYSTEM_CONTENT', 'Your default system content here')

        # File Handling Settings
        self.create_individual_files = os.getenv('CREATE_INDIVIDUAL_FILES', 'True').lower() == 'true'
        self.create_prompt_list = os.getenv('CREATE_PROMPT_LIST', 'True').lower() == 'true'
        self.create_master_files = os.getenv('CREATE_MASTER_FILES', 'True').lower() == 'true'
        self.list_file_mode = os.getenv('LIST_FILE_MODE', 'w')
        self.master_analysis_filename = os.getenv('MASTER_ANALYSIS_FILENAME', 'master_analysis.json')
        self.process_json_without_images = os.getenv('PROCESS_JSON_WITHOUT_IMAGES', 'False').lower() == 'true'

        # Image File Extensions
        self.image_file_extensions = os.getenv('IMAGE_FILE_EXTENSIONS', '.png,.jpg,.jpeg').split(',')

        # LLM Configurations
        self.llms = self._load_llm_configs()

        # Analysis Control
        self.clip_enabled = os.getenv('ENABLE_CLIP_ANALYSIS', 'True').lower() == 'true'
        self.llm_enabled = os.getenv('ENABLE_LLM_ANALYSIS', 'False').lower() == 'true'
        self.enable_json_processing = os.getenv('ENABLE_JSON_PROCESSING', 'True').lower() == 'true'

        # Retry Configuration
        self.retry_limit = int(os.getenv('RETRY_LIMIT', '5'))
        self.sleep_interval = int(os.getenv('SLEEP_INTERVAL', '5'))

        # LLM Parameters
        self.temperature = float(os.getenv('TEMPERATURE', '0.7'))
        self.max_tokens = int(os.getenv('MAX_TOKENS', '300'))
        self.top_p = float(os.getenv('TOP_P', '1.0'))
        self.frequency_penalty = float(os.getenv('FREQUENCY_PENALTY', '0.0'))
        self.presence_penalty = float(os.getenv('PRESENCE_PENALTY', '0.0'))

        # Selected Prompts
        self.selected_prompts = [p for p in os.getenv('SELECTED_PROMPTS', '').split(',') if p]

        # New Analysis Modes
        self.enable_caption = os.getenv('ENABLE_CAPTION', 'True').lower() == 'true'
        self.enable_best = os.getenv('ENABLE_BEST', 'True').lower() == 'true'
        self.enable_fast = os.getenv('ENABLE_FAST', 'True').lower() == 'true'
        self.enable_classic = os.getenv('ENABLE_CLASSIC', 'True').lower() == 'true'
        self.enable_negative = os.getenv('ENABLE_NEGATIVE', 'True').lower() == 'true'

        # Additional settings
        self.process_json_to_txt = os.getenv('PROCESS_JSON_TO_TXT', 'True').lower() == 'true'

    def _load_llm_configs(self) -> Dict[str, Dict[str, Any]]:
        llms = {}
        for i in range(1, 5):  # Assuming a maximum of 4 LLM configurations
            enabled = os.getenv(f'LLM_{i}_ENABLED', 'False').lower() == 'true'
            if enabled:
                llms[f'LLM_{i}'] = {
                    'api_url': os.getenv(f'LLM_{i}_API_URL'),
                    'api_key': os.getenv(f'LLM_{i}_API_KEY'),
                }
        return llms

    def get_openai_api_key(self) -> str:
        return self.openai_api_key  # Make sure this attribute is set in the __init__ method

    def get_prompt_options(self, prompt_id: str) -> Dict[str, Any]:
        return {
            'PROMPT_TEXT': os.getenv(f'{prompt_id.upper()}_PROMPT_TEXT', 'Default prompt text'),
            'TEMPERATURE': float(os.getenv(f'{prompt_id.upper()}_TEMPERATURE', str(self.temperature))),
            'MAX_TOKENS': int(os.getenv(f'{prompt_id.upper()}_MAX_TOKENS', str(self.max_tokens)))
        }

    def _get_enabled_modes(self):
        return [mode for mode, enabled in {
            'caption': self.enable_caption,
            'best': self.enable_best,
            'fast': self.enable_fast,
            'classic': self.enable_classic,
            'negative': self.enable_negative
        }.items() if enabled]

    def __str__(self) -> str:
        return f"""
        Configuration:
        - API Base URL: {self.api_base_url}
        - Timeout: {self.timeout}
        - Image Directory: {self.image_directory}
        - Output Directory: {self.output_directory}
        - CLIP Model: {self.clip_model_name}
        - CLIP Mode: {self.clip_mode}
        - LLM Model: {self.llm_model}
        - Enable CLIP Analysis: {self.enable_clip_analysis}
        - Enable LLM Analysis: {self.enable_llm_analysis}
        - Enable JSON Processing: {self.enable_json_processing}
        """


###### FILENAME: image_utils.py ######

import base64
import hashlib
import logging
from typing import Optional
import os

def generate_unique_code(image_path: str) -> str:
    """
    Generates a unique MD5 hash for the given image file.

    Args:
        image_path (str): The path to the image file.

    Returns:
        str: The MD5 hash of the image file.
    """
    try:
        with open(image_path, "rb") as f:
            file_hash = hashlib.md5()
            chunk = f.read(8192)
            while chunk:
                file_hash.update(chunk)
                chunk = f.read(8192)
        return file_hash.hexdigest()
    except Exception as e:
        logging.error(f"Error generating unique code for {image_path}: {str(e)}")
        return f"error_{os.path.basename(image_path)}"

def encode_image_to_base64(image_path: str) -> Optional[str]:
    """
    Encodes an image file to a base64 string.

    Args:
        image_path (str): The path to the image file.

    Returns:
        Optional[str]: The base64 encoded string of the image content, or None if an error occurs.
    """
    try:
        # Check if the file exists and is accessible
        if not os.path.exists(image_path):
            logging.error(f"Image file does not exist: {image_path}")
            return None

        # Read the image file in binary mode
        with open(image_path, 'rb') as image_file:
            encoded_string = base64.b64encode(image_file.read()).decode('utf-8')
            logging.info(f"Successfully encoded image to base64: {image_path}")
            return encoded_string
    except Exception as e:
        logging.error(f"Error encoding image to base64 {image_path}: {str(e)}")
        return None

# Keep other existing functions like resize_image


###### FILENAME: json_utils.py ######

import os
import json
import logging
from typing import Dict, Any, List, Set

def save_json(file_path: str, data: Dict[str, Any]) -> None:
    try:
        if os.path.exists(file_path):
            with open(file_path, 'r', encoding='utf-8') as json_file:
                existing_data = json.load(json_file)
            
            # Update file_info
            existing_data['file_info'] = data['file_info']
            
            # Merge analysis results
            for mode, result in data['analysis'].items():
                if mode not in existing_data['analysis']:
                    existing_data['analysis'][mode] = result
                elif result['model'] != existing_data['analysis'][mode]['model']:
                    existing_data['analysis'][f"{mode}_{result['model']}"] = result
            
            data = existing_data
        
        with open(file_path, 'w', encoding='utf-8') as json_file:
            json.dump(data, json_file, ensure_ascii=False, indent=4)
        logging.info(f"JSON output created/updated: {file_path}")
    except IOError as e:
        logging.error(f"Failed to create or write to file: {e}, Path attempted: {file_path}")

def get_existing_json_files(directory: str) -> Set[str]:
    json_files = set()
    for root, _, files in os.walk(directory):
        for file in files:
            if file.lower().endswith('.json'):
                json_files.add(file)
    return json_files

def should_process_file(file_path: str, existing_files: List[str], analyzer_name: str, config) -> bool:
    json_filename = f"{os.path.splitext(os.path.basename(file_path))[0]}_{analyzer_name}.json"
    if json_filename in existing_files:
        json_path = os.path.join(config.output_directory, json_filename)
        if os.path.exists(json_path):
            with open(json_path, 'r') as f:
                existing_data = json.load(f)
            
            # Check if all caption types are already processed
            existing_types = set(existing_data.get('analysis', {}).keys())
            required_types = set(config.caption_types)
            
            if required_types.issubset(existing_types):
                logging.info(f"Skipping {file_path}, all required caption types already processed.")
                return False
    return True

def process_json_to_txt(config, json_data: Dict[str, Any], output_dir: str):
    if not config.process_json_to_txt:
        return
        return
    filename = json_data['file_info']['filename']
    base_name = os.path.splitext(filename)[0]
    base_name = os.path.splitext(filename)[0]
    for mode, content in json_data['analysis'].items():
        if isinstance(content, str):
            txt_filename = f"{base_name}_{mode}.txt"
            txt_path = os.path.join(output_dir, txt_filename)
            with open(txt_path, 'w', encoding='utf-8') as f:
                f.write(content)
            logging.info(f"Created txt file: {txt_path}")

def process_existing_json_files(config):
    logging.info("Processing existing JSON files...")
    json_files = get_existing_json_files(config.image_directory)
    
    for json_file in json_files:
        file_path = os.path.join(config.image_directory, json_file)
        try:
            with open(file_path, 'r') as f:
                data = json.load(f)
            
            # Process the JSON data as needed, but don't create any txt files
            # You can add any necessary processing logic here
            
            logging.info(f"Processed {json_file}")
        except Exception as e:
            logging.error(f"Error processing {json_file}: {str(e)}")
    
    logging.info("Finished processing existing JSON files")


###### FILENAME: llm_analyzer.py ######

import os
import logging
import requests
from typing import Optional, Dict, Any, List
from analyzer import Analyzer
from api_utils import retry_with_backoff, log_api_conversation
from image_utils import encode_image_to_base64
import json_utils

class LLMAnalyzer(Analyzer):
    def __init__(self, config):
        super().__init__(config.image_directory)
        self.config = config
        self.logger = logging.getLogger('LLM_API')

    @retry_with_backoff(max_retries=5, initial_wait=1, backoff_factor=2)
    def send_llm_request(self, prompt: str) -> Optional[Dict[str, Any]]:
        headers = {"Content-Type": "application/json"}
        payload = {
            "prompt": prompt,
            "model": self.config.llm_model_name,
        }

        try:
            log_payload = {**payload, "prompt": "[PROMPT_CONTENT]"}
            self.logger.debug(f"Sending LLM request with payload: {log_payload}")

            response = requests.post(
                f"{self.config.api_base_url}/llm",
                json=payload,
                headers=headers,
                timeout=self.config.timeout
            )
            response.raise_for_status()
            response_data = response.json()
            return response_data
        except requests.HTTPError as e:
            self.logger.error(f"HTTP error occurred during LLM request: {e}")
            self.logger.error(f"Response content: {e.response.text if e.response else 'No response content'}")
            return None
        except requests.RequestException as e:
            self.logger.error(f"Error in LLM API request: {str(e)}")
            return None

    def process_images(self):
        existing_files = json_utils.get_existing_json_files(self.config.output_directory)
        for image_path in self.get_image_files():
            if json_utils.should_process_file(image_path, existing_files, self.__class__.__name__, self.config):
                for mode in self.config.selected_prompts:
                    prompt = self.create_prompt(image_path, mode)
                    result = self.send_llm_request(prompt)
                    if result is not None:
                        self.save_result(image_path, result)
                    else:
                        self.logger.warning(f"Skipping JSON creation for {image_path} due to LLM request error")

    def create_prompt(self, image_path: str, mode: str) -> str:
        # Create a prompt based on the image and mode
        return f"Analyze the image {image_path} in {mode} mode."

    def get_image_files(self):
        for root, _, files in os.walk(self.config.image_directory):
            for file in files:
                if file.lower().endswith(tuple(self.config.image_file_extensions)):
                    yield os.path.join(root, file)




###### FILENAME: logging_setup.py ######

import os
import logging

def setup_logging(config):
    """
    Setup logging configurations based on the configuration values.

    Args:
        config: Configuration object containing logging settings.

    This function sets up file and console logging, as well as specific loggers for API communication, CLIP API, and LLM API.
    """
    log_file = os.path.join(config.output_directory, 'analysis.log')
    os.makedirs(config.output_directory, exist_ok=True)

    # Create a custom logger
    logger = logging.getLogger()
    logger.setLevel(config.logging_level.upper())  # Use the logging level from config

    # Create handlers
    handlers = []
    if config.log_to_file:
        f_handler = logging.FileHandler(log_file, mode='a', encoding='utf-8')
        f_handler.setLevel(logging.DEBUG)
        handlers.append(f_handler)
    if config.log_to_console:
        c_handler = logging.StreamHandler()
        c_handler.setLevel(logging.INFO)
        handlers.append(c_handler)

    # Create a consistent formatter with short time format
    formatter = logging.Formatter(
        fmt='%(asctime)s - %(levelname)s - %(name)s - %(message)s',
        datefmt='%H:%M:%S'
    )

    for handler in handlers:
        handler.setFormatter(formatter)
        logger.addHandler(handler)

    # Suppress logging from PIL and other noisy libraries
    logging.getLogger('PIL').setLevel(logging.WARNING)
    logging.getLogger('urllib3').setLevel(logging.WARNING)  # Suppress urllib3 DEBUG logs

    # Setup API logging
    if config.log_to_file:
        api_logger = logging.getLogger('API')
        api_logger.setLevel(logging.DEBUG)
        api_handler = logging.FileHandler(os.path.join(config.output_directory, 'api_communication.log'), mode='w', encoding='utf-8')
        api_handler.setFormatter(formatter)
        api_logger.addHandler(api_handler)

        # Setup CLIP API logger
        clip_logger = logging.getLogger('CLIP_API')
        clip_logger.setLevel(logging.DEBUG)
        clip_handler = logging.FileHandler(os.path.join(config.output_directory, 'api_clip.log'), mode='w', encoding='utf-8')
        clip_handler.setFormatter(formatter)
        clip_logger.addHandler(clip_handler)

        # Setup LLM API logger if needed
        llm_logger = logging.getLogger('LLM_API')
        llm_logger.setLevel(logging.DEBUG)
        llm_handler = logging.FileHandler(os.path.join(config.output_directory, 'api_llm.log'), mode='w', encoding='utf-8')
        llm_handler.setFormatter(formatter)
        llm_logger.addHandler(llm_handler)



###### FILENAME: TEST.py ######

import requests  # Import the requests library to make HTTP requests
import base64  # Import base64 for encoding images
import os  # Import os for file path operations
import json  # Import json for handling JSON data

def encode_image_to_base64(image_path: str) -> str:
    """
    Encodes an image file to a base64 string.

    Args:
        image_path (str): The path to the image file.

    Returns:
        str: The base64 encoded string of the image.
    """
    with open(image_path, "rb") as image_file:  # Open the image file in binary read mode
        return base64.b64encode(image_file.read()).decode('utf-8')  # Encode the image and decode to UTF-8 string

def save_json(data, filename: str):
    """
    Saves data to a JSON file.

    Args:
        data: The data to save (usually a dictionary).
        filename (str): The name of the file to save the data to.
    """
    with open(filename, 'w') as f:  # Open the file in write mode
        json.dump(data, f, indent=4)  # Write the data to the file in JSON format with indentation
    print(f"Saved output to {filename}")  # Print confirmation of save

def analyze_image(image_path: str, api_base_url: str, model: str, timeout: int = 60):
    """
    Sends an image to the CLIP API for analysis.

    Args:
        image_path (str): The path to the image file.
        api_base_url (str): The base URL of the API.
        model (str): The model name to use for analysis.
        timeout (int): The timeout for the API request (default is 60 seconds).

    Returns:
        dict: The JSON response from the API containing analysis results.
    """
    image_base64 = encode_image_to_base64(image_path)  # Encode the image to base64
    
    # Prepare the payload for the API request
    payload = {
        "image": image_base64,  # The base64 encoded image
        "model": model  # The model to use for analysis
    }
    
    headers = {"Content-Type": "application/json"}  # Set the content type to JSON
    
    # Make a POST request to the API for analysis
    response = requests.post(
        f"{api_base_url}/interrogator/analyze",  # API endpoint for analysis
        json=payload,  # The payload containing the image and model
        headers=headers,  # The headers for the request
        timeout=timeout  # Timeout for the request
    )
    response.raise_for_status()  # Raise an error for bad responses (4xx or 5xx)
    return response.json()  # Return the JSON response from the API

def prompt_image(image_path: str, api_base_url: str, model: str, mode: str, timeout: int = 60):
    """
    Sends an image to the CLIP API to generate a prompt.

    Args:
        image_path (str): The path to the image file.
        api_base_url (str): The base URL of the API.
        model (str): The model name to use for generating prompts.
        mode (str): The mode for prompt generation (e.g., 'fast', 'best').
        timeout (int): The timeout for the API request (default is 60 seconds).

    Returns:
        dict: The JSON response from the API containing prompt results.
    """
    image_base64 = encode_image_to_base64(image_path)  # Encode the image to base64
    
    # Prepare the payload for the API request
    payload = {
        "image": image_base64,  # The base64 encoded image
        "model": model,  # The model to use for generating prompts
        "mode": mode  # The mode for prompt generation
    }
    
    headers = {"Content-Type": "application/json"}  # Set the content type to JSON
    
    # Make a POST request to the API for prompt generation
    response = requests.post(
        f"{api_base_url}/interrogator/prompt",  # API endpoint for prompt generation
        json=payload,  # The payload containing the image, model, and mode
        headers=headers,  # The headers for the request
        timeout=timeout  # Timeout for the request
    )
    response.raise_for_status()  # Raise an error for bad responses (4xx or 5xx)
    return response.json()  # Return the JSON response from the API

def main():
    # Configuration
    api_base_url = "http://localhost:7860"  # Change if your API runs on a different URL
    model = "ViT-L-14"  # Change to the model you are using
    mode = "fast"  # Mode for prompt; can be 'fast', 'best', 'classic', 'negative', 'caption'
    image_filename = "test.png"  # Replace with your image filename
    
    # Check if image exists
    if not os.path.isfile(image_filename):  # Verify that the image file exists
        print(f"Image file {image_filename} not found in the current directory.")
        return
    
    # Analyze the image
    try:
        analysis_result = analyze_image(image_filename, api_base_url, model)
        save_json(analysis_result, "analyze_output.json")
    except Exception as e:
        print(f"An error occurred during analysis: {e}")
    
    # Generate prompt from the image
    try:
        prompt_result = prompt_image(image_filename, api_base_url, model, mode)
        save_json(prompt_result, "prompt_output.json")
    except Exception as e:
        print(f"An error occurred during prompt generation: {e}")

if __name__ == "__main__":
    main()


###### FILENAME: utils.py ######

import base64
import hashlib
import requests
import os
import logging
from functools import wraps
from PIL import Image
import io
from typing import Optional, Dict, Any, Callable

def safe_api_call(func: Callable) -> Callable:
    """
    Decorator to safely handle API calls and log errors.
    """
    @wraps(func)
    def wrapper(*args, **kwargs):
        try:
            return func(*args, **kwargs)
        except requests.RequestException as e:
            logging.error(f"API request failed: {str(e)}")
            return {"error": str(e)}
        except Exception as e:
            logging.exception(f"Unexpected error in API call: {str(e)}")
            return {"error": "An unexpected error occurred"}
    return wrapper

def validate_directory(directory: str) -> None:
    """
    Validate if a directory exists and is accessible.
    """
    if not os.path.isdir(directory):
        raise ValueError(f"The specified path is not a valid directory: {directory}")
    if not os.access(directory, os.R_OK):
        raise PermissionError(f"You don't have read permissions for the directory: {directory}")


