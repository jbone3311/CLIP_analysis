## Directory Structure ##
./
    .env
    .gitignore
    analysis_main.py
    analyzer.py
    api_utils.py
    Before Refactor (OLD CODE).zip
    clip_analyzer.py
    CodeSheetConfig.ini
    Code_From_CWD.txt
    config.py
    Dir_Structure.txt
    image_utils.py
    json_utils.py
    llm_analyzer.py
    LLM_CodeSheetV2.exe
    logging_setup.py
    utils.py
    .git/
        COMMIT_EDITMSG
        config
        description
        FETCH_HEAD
        HEAD
        index
        ORIG_HEAD
        hooks/
            applypatch-msg.sample
            commit-msg.sample
            fsmonitor-watchman.sample
            post-update.sample
            pre-applypatch.sample
            pre-commit.sample
            pre-merge-commit.sample
            pre-push.sample
            pre-rebase.sample
            pre-receive.sample
            prepare-commit-msg.sample
            push-to-checkout.sample
            update.sample
        info/
            exclude
        logs/
            HEAD
            refs/
                heads/
                    main
                remotes/
                    origin/
                        main
        objects/
            01/
                363af75eef02ef1dfe65d39d7dc2927ec113b8
            06/
                f0cfda7d8b1490d0602d0a251ba23ddd083e1a
            09/
                b55fca364bc89b6bda729320fe45e2e4a61f5e
            0a/
                7ac1a4e73c95918a4f207740529fad15bd6f79
            14/
                143012ca8153a65b874692a7593376d731ea99
            17/
                1c35e99f5fabe2d12bf39568f56ef5e4bda197
            1a/
                62411753d4eb1b19712bffd299a390c08121e4
            20/
                8fdd5f53a04175ce4eeca994ff0a0373654475
            21/
                8087db7dc42d4b59095e693f098aa95afca11e
            28/
                1d703ca8a5e6418ab67f938ae8057f971bf80d
            2a/
                cc6e4ed4d6f4d7f288927a6ccdd401279e7772
            2c/
                fd812683bb4fdf6001036cd2e00a094d8ecbce
            2e/
                a313fbd02d944d30b438b31f80bc4e1dc2db80
                b037b49e9a5830d449588525ba62f54a8d4372
            2f/
                85059977ee9d5233b15cb94ea0c4a29816e365
            33/
                5a859abbddcf85ddcc458b7f3b7db482838cf4
            3a/
                0f13e0500d93ae06abecdf94050e2d6af326b4
            3f/
                2c76c4b88c79d6df4de57c222b671bc4acdd34
            43/
                1a30a922f1ef2c666f42e8fe7b9ca3504cb1f3
            44/
                ae09b40013728d0071e07ed89b660dd14cbd0c
            46/
                accc6aed2be2b2c358fbfd3d9846a45e42e15b
            4a/
                9a2d86738ed2a39105a3788850ef385aa640a7
                ed745baa7e38a63bb7302b5f640855cde8e679
            4b/
                14f6ceaf1225250abff5fdb7aea8d89e2ecaf9
            4c/
                05e6aa8483cd23c67c2397bf8a59eb4809ec95
            4e/
                86f0211bbc4e2e5e6a9f6afb2c49fef903d894
                9effc7b30be4839161c70452622a11e443e96c
            51/
                d1d770fff8a73b002e5e3e215755aaf1bdbe1a
            52/
                694e94af0c0105262746eeb9181a660eeed06c
            53/
                77a3dd45c706f304d0d2499685ceae792c492d
            54/
                a83c5cc6112abb8e0ee6a85dc3f4d5c4228415
            55/
                502ad96551fea27292a1205fb34b97760a0c0d
            56/
                5030af84d2c8ab2949905806a6c99dd0776446
            61/
                5bb3be1143988082690293e03c5b36e6747a58
            65/
                716bf88866d42cb1f5cef4c514887d19445afb
            69/
                c8d00bcf98864c3c91e4a3296ec0d6b386b0a9
            6b/
                769b87c40351060454e1b84a9daa5cdb524aad
            6d/
                18c9c2c08f8cbd79e8c352d0e2973a22427679
            72/
                70cc991c88a7347b64e3ec42a84a9734ad6259
                e4833b738a5572dbedad149277f07720e5a50e
            73/
                15aab94c64699b12a627f26dacb02f8c9c0d78
            7b/
                50f2ae5e7f7211dc1f6949e6312f11512989aa
            7d/
                1c6434bb60de5226147d616ef01015e76000f0
            7e/
                8c35f7895bbf25ce2ee4261ec452edbb208f03
            81/
                34429f5efbc0ed84cbf64affa2cf35a34bdd25
            83/
                3543101dbaae482f79d04f022be1faeca1a3a3
            85/
                33268ec2390c8eeae927d4dabc425f81aa35c6
                f7b1098fbd59ed03a3881be001556d46fc845e
            8e/
                51200d0afc7bb0a5ef144342941835a007ea23
            90/
                c5250571b418089881d0b370cb55a907b017f4
                e84a4dffe271af2d9148f99d0418dedc9af356
            97/
                149e0b7f0469fbc9779b9cce95d01cf7a5936d
            98/
                1b97272287ef06f7cbd808f559a9b39add68ad
            9c/
                db5cf19b5cf482f2d42c36b834006ef1c2958d
            9d/
                746a318e38dac971deb5009d8512325d1da827
            a3/
                027d680fb49487f69498a9c66d1bb9efdb0237
            a4/
                5b147aff201a09ee8e9d2d13b10bfcb8b2e8ff
            a7/
                1511e577aba3df3db583474232e2c5889bc739
                db5c341cae337b13d55a0c0bb12d0e8efb1d46
            aa/
                658af92755e48a2fbdb812f4190715a2a77cf0
            ad/
                67d44dc5247004866e1d24e8f9b08e4416dbbc
                b7e5d4e5c042d57d92efc7af0bb20a4fc96400
            ae/
                ab11aae483224397c149b7475b70d138065749
                ba0cf0a3eec7eea9ab7772ffe930d2ca397510
            af/
                34c0b5a9696a6c974eb00da64c9180a776be28
            b2/
                f60574e41d7d2978e9cdd927c23cc1ec8e5ba7
            b3/
                84f7fb77024b52f25c6ad199cf21c13c88e8a5
            b4/
                fc0b239360654a3a8648c9ccde04146861d5e0
            b5/
                8088ca3135ea3e2f7d4b02ee2265545c46b989
            bb/
                542e24557ff8f99a31532d7d3e8489886093d0
            bc/
                fa9923e522703fea3e83c4483b1f345ae6dfab
            c2/
                4eaeaff48e0ebdc13ffbca84dd7e132fedc7d5
            c5/
                aab2196d73c5947a78a3747f760c55c4b818cb
            c6/
                b5f3dceaec9e009841aedca32685ee0b8e5f85
            c9/
                48b53fa029eb204d6f2970e3bddadf680ae8f8
            ca/
                4bbc13a7698526ed65bac1e5f89a00d5c0ed27
            d4/
                8ecf06614c250592352cf7a48f84ae2aa11b91
            d6/
                ef30e2314f2251d3c873ae82703ec1823e4e78
                f9ac1143e5a83fb9098f1c9d9962b4a4ff58a3
            dc/
                cdfff6a508dced40da8f154dc86d45b09d1ba9
            df/
                ff068b1634dd3ab77befb0ab3bc80f1ac44386
            e6/
                ac88c99108d0a3c782c62f4ca1782ccdf90e44
                f53c5789c536767397f11de18cb4135fe9712c
            e7/
                149f6a5e0642d4a0feb1d2b19e240e898bac91
            e9/
                c598f088daf091434a18a9d40b8d850a17a979
            eb/
                2519db0f8902504097140f8158ce293c2e9110
            ec/
                cf94bbb9e32d164fda7f37cf066bc5c7c68dc3
                e5edab650abc7f8644c76cb807251ba0ec8512
            ed/
                622d6f6c5b5c3cbd39a7fbbf9c92d0e9eaad27
                7a416949d6e9e2210f9b6b0ce80567b88ebdf1
            f3/
                03345aab6ab56c019888d5fe3589440af8bbaf
            f7/
                f58c77405e25b3061c8ed0bcccff1c96eb4847
            fb/
                60d4b3b1ffe94e3056b9ae7d827709aeb7bd5d
            ff/
                2668437496ced2701b56bf8cd2992c76575fef
                362cbcbd5616d12a6f2dcd4349713b66590e0a
            info/
            pack/
        refs/
            heads/
                main
            remotes/
                origin/
                    main
            tags/
    Images/
        1/
            RANDOS (30).png
            json/
                1_RANDOS (30)_clip_analysis.json
        2/
            FarSide (26).jpg
            RANDOS (20).png
            json/
                2_FarSide (26)_clip_analysis.json
                2_RANDOS (20)_clip_analysis.json
        test/
            FarSide (81).jpg
            sample.jpg
            json/
                test_FarSide (81)_clip_analysis.json
                test_sample_clip_analysis.json
    Output/
        api_communication_log.json
        Log.log
        CLIP_analysis/
            1_best_Prompts.txt
            1_caption_Prompts.txt
            1_classic_Prompts.txt
            1_fast_Prompts.txt
            1_negative_Prompts.txt
            2_best_Prompts.txt
            2_caption_Prompts.txt
            2_classic_Prompts.txt
            2_fast_Prompts.txt
            2_negative_Prompts.txt
            test_best_Prompts.txt
            test_caption_Prompts.txt
            test_classic_Prompts.txt
            test_fast_Prompts.txt
            test_negative_Prompts.txt

## Main Directory ##

###### FILENAME: analysis_main.py ######

import logging
import time
from dotenv import load_dotenv
from config import Config
from logging_setup import setup_logging
from clip_analyzer import CLIPAnalyzer
from llm_analyzer import LLMAnalyzer
from json_utils import process_existing_json_files
from api_utils import test_api

load_dotenv()

def main():
    try:
        config = Config()
        setup_logging(config)

        logging.info("### Processing New Batch ###")

        api_base_url = config.api_base_url
        timeout = config.timeout

        for attempt in range(3):
            if test_api(api_base_url, timeout):
                logging.info("API is responsive and working.")
                clip_analyzer = CLIPAnalyzer(config)
                clip_analyzer.process_images()
                llm_analyzer = LLMAnalyzer(config)
                llm_analyzer.process_images()
                break
            else:
                logging.warning(f"API at {api_base_url} is not responsive. Attempt {attempt + 1} failed.")
                time.sleep(2 ** attempt)  # Exponential backoff
        else:
            logging.error(f"API at {api_base_url} is not responsive after 3 attempts. Skipping image processing.")

        process_existing_json_files(config)

    except Exception as e:
        logging.exception(f"An unexpected error occurred: {str(e)}")

if __name__ == "__main__":
    main()


###### FILENAME: analyzer.py ######

import os
import json
import logging
import time
from abc import ABC, abstractmethod
from typing import Dict, Set, List

class Analyzer(ABC):
    """
    Abstract base class for image analyzers.
    
    This class provides a common structure for different types of image analyzers,
    including methods for processing directories, handling existing files, and
    saving results. Subclasses should implement the `analyze_image` method.
    """

    def __init__(self, directory: str):
        self.directory = directory
        logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

    @abstractmethod
    def analyze_image(self, image_path: str) -> Dict:
        pass

    def get_existing_json_files(self) -> Set[str]:
        existing_files = set()
        for root, _, files in os.walk(self.directory):
            for file in files:
                if file.endswith('.json'):
                    existing_files.add(file)
        return existing_files

    def process_directory(self) -> None:
        start_time = time.time()
        existing_files = self.get_existing_json_files()
        total_images = sum(len(files) for _, _, files in os.walk(self.directory) 
                           if any(f.lower().endswith(('.png', '.jpg', '.jpeg')) for f in files))
        processed_images = 0

        for root, _, files in os.walk(self.directory):
            for file in files:
                if file.lower().endswith(('.png', '.jpg', '.jpeg')):
                    image_path = os.path.join(root, file)
                    if self.should_process_file(file, existing_files):
                        try:
                            result = self.analyze_image(image_path)
                            self.save_result(image_path, result)
                            processed_images += 1
                            logging.info(f"Processed {processed_images}/{total_images}: {file}")
                        except Exception as e:
                            logging.error(f"Error processing {image_path}: {e}")

        total_time = time.time() - start_time
        logging.info(f"Total processing time: {total_time:.2f} seconds")
        logging.info(f"Processed {processed_images}/{total_images} images")

    def save_result(self, image_path: str, result: Dict) -> None:
        json_path = f"{os.path.splitext(image_path)[0]}_{self.__class__.__name__}.json"
        self.ensure_output_directory(os.path.dirname(json_path))
        with open(json_path, 'w') as f:
            json.dump(result, f, indent=2)
        logging.info(f"Saved results to {json_path}")

    def should_process_file(self, file: str, existing_files: Set[str]) -> bool:
        json_filename = f"{os.path.splitext(file)[0]}_{self.__class__.__name__}.json"
        if json_filename in existing_files:
            logging.info(f"Skipping {file}, JSON already exists.")
            return False
        return True

    def ensure_output_directory(self, path: str) -> None:
        os.makedirs(path, exist_ok=True)

    def get_image_files(self) -> List[str]:
        image_files = []
        for root, _, files in os.walk(self.image_directory):
            for file in files:
                if file.lower().endswith(('.png', '.jpg', '.jpeg', '.gif')):
                    image_files.append(os.path.join(root, file))
        return image_files



###### FILENAME: api_utils.py ######

import os
import requests
import logging
from typing import Dict, Any
from dotenv import load_dotenv
from functools import wraps
from utils import safe_api_call

load_dotenv()

# Function to test the API
def test_api(api_base_url: str, timeout: int) -> bool:
    """
    Test the API by hitting the health endpoint.
    
    :param api_base_url: Base URL of the API.
    :param timeout: Timeout duration for the request.
    :return: True if the API is responsive, False otherwise.
    """
    try:
        response = requests.get(f"{api_base_url}/health", timeout=timeout)
        return response.status_code == 200
    except requests.RequestException:
        return False

# Function to send a request to the LLM API
@safe_api_call
def send_llm_request(data: Dict[str, Any], api_key: str) -> Dict[str, Any]:
    """
    Send a request to the LLM API.

    :param data: The payload to send to the API.
    :param api_key: The API key for authentication.
    :return: The response from the API.
    """
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {api_key}"
    }
    api_url = os.getenv('LLM_API_URL', 'http://default-llm-url.com')
    try:
        response = requests.post(data['api_url'], json=data['payload'], headers=headers, timeout=data['timeout'])
        response.raise_for_status()
        return response.json()
    except requests.RequestException as e:
        logging.error(f"Error in LLM API request: {str(e)}")
        return None

# Function to check if the LLM JSON data is valid
def is_llm_json_valid(json_data: dict) -> bool:
    """
    Check if the LLM JSON data is valid.

    :param json_data: The JSON data to check.
    :return: True if the data is valid, False otherwise.
    """
    required_keys = ['model', 'messages', 'temperature', 'max_tokens']
    return all(key in json_data for key in required_keys)

# Function to create the data payload for the LLM request
def create_data(image_url: str, prompt_text: str, temperature: float, max_tokens: int, role: str, system_content: str, model: str, top_p: float = 1.0, frequency_penalty: float = 0.0, presence_penalty: float = 0.0) -> dict:
    """
    Create the data payload for the LLM request.

    :param image_url: The URL of the image.
    :param prompt_text: The prompt text to send to the LLM.
    :param temperature: The temperature setting for the LLM.
    :param max_tokens: The maximum number of tokens for the LLM response.
    :param role: The role of the message sender.
    :param system_content: The system content for the LLM.
    :param model: The model to use for the LLM.
    :param top_p: The top-p setting for the LLM.
    :param frequency_penalty: The frequency penalty setting for the LLM.
    :param presence_penalty: The presence penalty setting for the LLM.
    :return: The data payload as a dictionary.
    """
    return {
        "model": model,
        "messages": [
            {
                "role": role,
                "content": [
                    {"type": "text", "text": prompt_text},
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": image_url
                        }
                    }
                ]
            }
        ],
        "temperature": temperature,
        "max_tokens": max_tokens,
        "top_p": top_p,
        "frequency_penalty": frequency_penalty,
        "presence_penalty": presence_penalty
    }

# Function to analyze an image in detail by sending it to the API with multiple caption types
@safe_api_call
def analyze_image_detailed(image_base64: str, model: str, caption_types: list, api_url: str, timeout: int, config) -> Dict[str, Any]:
    """
    Send a request to analyze an image using the CLIP model.
    """
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {os.getenv('OPENAI_API_KEY')}"
    }
    payload = {
        "model": model,
        "image": image_base64,
        "detailed": True,
        "caption_types": caption_types
    }
    response = requests.post(f"{api_url}/interrogator/prompt", json=payload, headers=headers, timeout=timeout)
    response.raise_for_status()
    return response.json()

# Other functions in api_utils.py remain unchanged


###### FILENAME: clip_analyzer.py ######

import os
import logging
import traceback
from typing import Dict, Any
from dotenv import load_dotenv
from analyzer import Analyzer
from utils import encode_image_to_base64, generate_unique_code
from api_utils import analyze_image_detailed

load_dotenv()

class CLIPAnalyzer(Analyzer):
    def __init__(self, config):
        super().__init__(config.image_directory)
        self.config = config
        self.api_base_url = config.api_base_url
        self.timeout = config.timeout

    def analyze_image(self, image_path: str) -> Dict[str, Any]:
        try:
            image_base64 = encode_image_to_base64(image_path)
            unique_code = generate_unique_code(image_path)
            subdir = os.path.basename(os.path.dirname(image_path))
            file = os.path.basename(image_path)
            
            detailed_results = {
                'filename': file,
                'unique_code': unique_code,
                'directory_name': subdir,
                'model': self.config.model,
                'prompts': {},
                'analysis': {}
            }
            
            analysis_result = analyze_image_detailed(image_base64, self.config.model, self.config.caption_types, self.api_base_url, self.timeout, self.config)
            detailed_results['analysis'] = analysis_result
            
            return detailed_results
        except FileNotFoundError:
            logging.error(f"Image file not found: {image_path}")
            return {'error': 'File not found'}
        except PermissionError:
            logging.error(f"Permission denied when accessing: {image_path}")
            return {'error': 'Permission denied'}
        except Exception as e:
            logging.error(f"Unexpected error analyzing image {image_path}: {str(e)}")
            logging.debug(f"Traceback: {traceback.format_exc()}")
            return {'error': 'Unexpected error', 'details': str(e)}

    def process_images(self):
        for image_path in self.get_image_files():
            result = self.analyze_image(image_path)
            # Process the result as needed

def process_clip_images(config) -> None:
    analyzer = CLIPAnalyzer(config)
    analyzer.process_directory()



###### FILENAME: config.py ######

import os
from dotenv import load_dotenv

load_dotenv()

def mask_api_key(api_key):
    """Mask the API key for secure logging."""
    if len(api_key) < 6:
        return "*" * len(api_key)
    return api_key[:3] + "*" * (len(api_key) - 6) + api_key[-3:]

class Config:
    """
    Configuration handler to load and manage application settings.
    """

    def __init__(self):
        self.load_config()

    def load_config(self):
        """
        Load configuration from environment variables.
        """
        # API Keys
        self.serper_api_key = os.getenv('SERPER_API_KEY')
        self.openai_api_key = self.get_openai_api_key()
        self.google_api_key = os.getenv('GOOGLE_API_KEY')
        self.google_cse_id = os.getenv('GOOGLE_CSE_ID')
        self.agentops_api_key = os.getenv('AGENTOPS_API_KEY')

        # Local LLM Settings
        self.local_llm_model_path = os.getenv('LOCAL_LLM_MODEL_PATH')
        self.openai_api_base = os.getenv('OPENAI_API_BASE', 'https://api.openai.com/v1')
        self.openai_model_name = os.getenv('OPENAI_MODEL_NAME', 'gpt-3.5-turbo')

        # API Configuration
        self.api_base_url = os.getenv('API_BASE_URL', 'http://localhost:5000')
        self.timeout = int(os.getenv('TIMEOUT', '30'))

        # Directory Settings
        self.image_directory = os.getenv('IMAGE_DIRECTORY', 'Images')
        self.output_directory = os.getenv('OUTPUT_DIRECTORY', 'Output')

        # Logging Configuration
        self.logging_level = os.getenv('LOGGING_LEVEL', 'INFO')
        self.logging_format = os.getenv('LOGGING_FORMAT', '%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        self.log_to_console = os.getenv('LOG_TO_CONSOLE', 'True').lower() == 'true'
        self.log_to_file = os.getenv('LOG_TO_FILE', 'True').lower() == 'true'
        self.log_file = os.getenv('LOG_FILE', 'image_analysis.log')
        self.log_mode = os.getenv('LOG_MODE', 'a')
        self.log_api_communication = os.getenv('LOG_API_COMMUNICATION', 'False').lower() == 'true'

        # Model Settings
        self.model = os.getenv('MODEL', 'ViT-g-14/laion2B-s34B-b88K')
        self.caption_types = os.getenv('CAPTION_TYPES', 'caption,best,fast,classic,negative').split(',')

        # LLM Settings
        self.llm_api_base_url = os.getenv('LLM_API_BASE_URL', 'https://api.openai.com/v1/chat/completions')
        self.llm_model = os.getenv('LLM_MODEL', 'gpt-3.5-turbo')
        self.llm_system_content = os.getenv('LLM_SYSTEM_CONTENT', 'You are a helpful assistant.')

        # File Handling Settings
        self.create_individual_files = os.getenv('CREATE_INDIVIDUAL_FILES', 'True').lower() == 'true'
        self.create_prompt_list = os.getenv('CREATE_PROMPT_LIST', 'True').lower() == 'true'
        self.create_master_files = os.getenv('CREATE_MASTER_FILES', 'True').lower() == 'true'
        self.list_file_mode = os.getenv('LIST_FILE_MODE', 'w')
        self.master_analysis_filename = os.getenv('MASTER_ANALYSIS_FILENAME', 'master_analysis.json')
        self.process_json_without_images = os.getenv('PROCESS_JSON_WITHOUT_IMAGES', 'False').lower() == 'true'

        # Image File Extensions
        self.image_file_extensions = os.getenv('IMAGE_FILE_EXTENSIONS', '.png,.jpg,.jpeg').split(',')

        # LLM Configurations
        self.llms = {}
        for i in range(1, 5):
            enabled = os.getenv(f'LLM_{i}_ENABLED', 'False').lower() == 'true'
            if enabled:
                self.llms[f'LLM_{i}'] = {
                    'enabled': enabled,
                    'api_url': os.getenv(f'LLM_{i}_API_URL', ''),
                    'api_key': os.getenv(f'LLM_{i}_API_KEY', '')
                }

    def get_openai_api_key(self):
        """
        Get the OpenAI API key from the environment variable.
        """
        api_key = os.getenv('OPENAI_API_KEY', '')
        if not api_key:
            raise ValueError("OpenAI API Key not found in environment.")
        return api_key

    def get_prompt_options(self, prompt_id):
        """
        Get prompt options for a given prompt ID.
        """
        # This is a placeholder implementation. You should replace this with your actual prompt options logic.
        return {
            'PROMPT_TEXT': f'Default prompt text for {prompt_id}',
            'TEMPERATURE': 0.7,
            'MAX_TOKENS': 150
        }

    def __str__(self):
        """
        Return a string representation of the configuration, masking sensitive data.
        """
        return f"""
        Configuration:
        - Image Directory: {self.image_directory}
        - Output Directory: {self.output_directory}
        - API Base URL: {self.api_base_url}
        - OpenAI API Key: {mask_api_key(self.openai_api_key)}
        - Timeout: {self.timeout}
        - Logging Level: {self.logging_level}
        - Model: {self.model}
        - Caption Types: {', '.join(self.caption_types)}
        - LLM Model: {self.llm_model}
        - Create Individual Files: {self.create_individual_files}
        - Create Master Files: {self.create_master_files}
        - Image File Extensions: {', '.join(self.image_file_extensions)}
        """


###### FILENAME: image_utils.py ######

import base64
import hashlib
import logging
from PIL import Image, UnidentifiedImageError
from io import BytesIO

def generate_unique_code(image_path):
    """Generate a unique SHA-256 hash for an image file.

    Args:
        image_path (str): Path to the image file.

    Returns:
        str: SHA-256 hash of the image, or None if an error occurs.
    """
    try:
        with Image.open(image_path) as img:
            with BytesIO() as img_byte_array:
                img.save(img_byte_array, format=img.format)
                img_byte_data = img_byte_array.getvalue()
                return hashlib.sha256(img_byte_data).hexdigest()
    except FileNotFoundError as e:
        logging.error("Image file not found: %s - %s", image_path, e)
    except UnidentifiedImageError as e:
        logging.error("Cannot identify image file: %s - %s", image_path, e)
    except Exception as e:
        logging.error("Error generating unique code for image %s: %s", image_path, e)
    return None

def resize_image(image, max_size=(512, 512)):
    """Resize the image to fit within max_size while maintaining aspect ratio.

    Args:
        image (PIL.Image): Image to resize.
        max_size (tuple): Maximum width and height.

    Returns:
        PIL.Image: Resized image.
    """
    image.thumbnail(max_size, Image.ANTIALIAS)
    return image

def encode_image_to_base64(image_path):
    """Encode an image file to a base64 string.

    Args:
        image_path (str): Path to the image file.

    Returns:
        str: Base64 encoded string of the image, or None if an error occurs.
    """
    try:
        with Image.open(image_path) as img:
            img = resize_image(img)  # Resize the image before encoding
            imgio = BytesIO()
            img.save(imgio, 'JPEG')
            imgio.seek(0)
            data = base64.b64encode(imgio.read())
            return data.decode('utf8')
    except FileNotFoundError as e:
        logging.error("Image file not found: %s - %s", image_path, e)
    except UnidentifiedImageError as e:
        logging.error("Cannot identify image file: %s - %s", image_path, e)
    except Exception as e:
        logging.error("Error encoding image to base64: %s", e)
    return None

def process_image_for_analysis(image_path):
    """Process an image for analysis by resizing and converting to JPEG if needed.

    Args:
        image_path (str): Path to the image file.

    Returns:
        str: Base64 encoded string of the processed image, or None if an error occurs.
    """
    try:
        with Image.open(image_path) as img:
            # Check if the image is already 512x512 or smaller and in JPEG format
            if img.size[0] <= 512 and img.size[1] <= 512 and img.format == 'JPEG':
                return encode_image_to_base64(image_path)
            else:
                # Resize and convert to JPEG
                img = resize_image(img)
                imgio = BytesIO()
                img.save(imgio, 'JPEG')
                imgio.seek(0)
                data = base64.b64encode(imgio.read())
                return data.decode('utf8')
    except FileNotFoundError as e:
        logging.error("Image file not found: %s - %s", image_path, e)
    except UnidentifiedImageError as e:
        logging.error("Cannot identify image file: %s - %s", image_path, e)
    except Exception as e:
        logging.error("Error processing image for analysis: %s", e)
    return None


###### FILENAME: json_utils.py ######

import os
import json
import logging
import time

def save_json(file_path, data):
    """
    Save data to a JSON file.

    Args:
        file_path: Path to the JSON file.
        data: Data to be saved.
    """
    try:
        with open(file_path, 'w', encoding='utf-8') as json_file:
            json.dump(data, json_file, ensure_ascii=False, indent=4)
        logging.info(f"JSON output created: {file_path}")
    except IOError as e:
        logging.error(f"Failed to create or write to file: {e}, Path attempted: {file_path}")

def get_existing_json_files(directory):
    """
    Get the list of existing JSON files in the given directory.

    Args:
        directory: Directory to search for JSON files.

    Returns:
        list: List of JSON filenames found.
    """
    json_files = []
    for root, _, files in os.walk(directory):
        json_files.extend([file for file in files if file.lower().endswith('_clip_analysis.json')])
    return json_files

def process_existing_json_files(config):
    """
    Process existing JSON files and generate text files containing prompt lists.

    Args:
        config: Configuration object.
    """
    clip_analysis_dir = os.path.join(config.output_directory, 'CLIP_analysis')
    os.makedirs(clip_analysis_dir, exist_ok=True)

    for subdir in os.listdir(config.image_directory):
        subdir_path = os.path.join(config.image_directory, subdir)
        if os.path.isdir(subdir_path):
            logging.debug(f"Looking into JSON directory: {subdir_path}")
            batch_json_dir = os.path.join(subdir_path, 'json')
            if not os.path.exists(batch_json_dir):
                logging.info(f"JSON directory does not exist: {batch_json_dir}")
                continue
            else:
                logging.info(f"Found JSON directory: {batch_json_dir}")

            for root, _, files in os.walk(batch_json_dir):
                logging.debug(f"Processing existing JSON files in directory: {root}")
                prompt_lists = {caption_type: [] for caption_type in config.caption_types}

                json_files = [file for file in files if file.lower().endswith('_clip_analysis.json')]
                if not json_files:
                    logging.info(f"No JSON files found in {root}")
                    continue

                for json_file in json_files:
                    json_full_path = os.path.join(root, json_file)
                    logging.debug(f"Reading JSON file: {json_full_path}")
                    try:
                        with open(json_full_path, 'r', encoding='utf-8') as f:
                            data = json.load(f)
                    except Exception as e:
                        logging.error(f"Failed to read JSON file {json_full_path}: {e}")
                        continue

                    for caption_type in config.caption_types:
                        if caption_type in data.get('prompts', {}):
                            prompt = data['prompts'][caption_type]
                            if prompt:
                                prompt_lists[caption_type].append(prompt)

                if config.create_prompt_list:
                    for caption_type, prompts in prompt_lists.items():
                        if prompts:
                            list_filename = f"{subdir}_{caption_type}_Prompts.txt"
                            list_path = os.path.join(clip_analysis_dir, list_filename)
                            logging.debug(f"Writing prompt list file: {list_path}")
                            try:
                                with open(list_path, config.list_file_mode, encoding='utf-8') as f:
                                    f.write('\n'.join(prompts))
                                logging.info(f"{time.strftime('%d/%m/%y %H:%M')} {list_filename}")
                            except Exception as e:
                                logging.error(f"Failed to write to file {list_path}: {e}")


###### FILENAME: llm_analyzer.py ######

import os
import logging
from typing import Dict, Any
from dotenv import load_dotenv
from analyzer import Analyzer
from utils import encode_image_to_base64, generate_unique_code, safe_api_call
from api_utils import send_llm_request
load_dotenv()

class LLMAnalyzer(Analyzer):
    def __init__(self, config):
        super().__init__(config.image_directory)
        self.config = config

    def analyze_image(self, image_path: str) -> Dict[str, Any]:
        try:
            image_base64 = encode_image_to_base64(image_path)
            unique_code = generate_unique_code(image_path)
            subdir = os.path.basename(os.path.dirname(image_path))
            file = os.path.basename(image_path)
            
            llm_results = {}
            for llm_key, llm_config in self.config.llms.items():
                if llm_config['enabled']:
                    for prompt_id in self.config.selected_prompts:
                        data = self._prepare_llm_data(image_base64, prompt_id)
                        response = self.send_llm_request(data, llm_config['api_key'])
                        if response:
                            llm_results[f"{llm_key}_{prompt_id}"] = response['choices'][0]['message']['content']
                        else:
                            logging.warning(f"No response received for {llm_key}, prompt ID {prompt_id}.")
            
            return {
                'filename': file,
                'unique_code': unique_code,
                'directory_name': subdir,
                'llm_results': llm_results
            }
        except FileNotFoundError:
            logging.error(f"Image file not found: {image_path}")
            return {'error': 'File not found'}
        except PermissionError:
            logging.error(f"Permission denied when accessing: {image_path}")
            return {'error': 'Permission denied'}
        except Exception as e:
            logging.error(f"Unexpected error analyzing image {image_path}: {str(e)}")
            logging.debug(f"Traceback: {traceback.format_exc()}")
            return {'error': 'Unexpected error', 'details': str(e)}

    def _prepare_llm_data(self, image_base64: str, prompt_id: str) -> Dict[str, Any]:
        prompt_options = self.config.get_prompt_options(prompt_id)
        return {
            "model": self.config.llm_model,
            "messages": [
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": prompt_options['PROMPT_TEXT']},
                        {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{image_base64}"}}
                    ]
                }
            ],
            "temperature": prompt_options['TEMPERATURE'],
            "max_tokens": prompt_options['MAX_TOKENS'],
            "top_p": self.config.top_p,
            "frequency_penalty": self.config.frequency_penalty,
            "presence_penalty": self.config.presence_penalty
        }

    @safe_api_call
    def send_llm_request(self, data: Dict[str, Any], api_key: str) -> Dict[str, Any]:
        # Existing code without try-except block

    def process_images(self):
        # Implement the logic to process images here
        for image_path in self.get_image_files():
            result = self.analyze_image(image_path)
            # Process the result as needed

# Remove or comment out the following function
# def process_llm_images(config, api_base_url: str, timeout: int) -> None:
#     analyzer = LLMAnalyzer(config)
#     analyzer.process_directory()



###### FILENAME: logging_setup.py ######

import os
import logging

def setup_logging(config):
    """
    Setup logging configurations based on the configuration values.
    """
    log_to_file = config.log_to_file
    log_to_console = config.log_to_console
    log_file = config.log_file
    log_mode = config.log_mode
    output_directory = config.output_directory

    logging.getLogger().handlers.clear()

    log_format = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s', datefmt='%d/%m/%y %H:%M')
    console_log_format = logging.Formatter('%(message)s')

    if log_to_file:
        log_file_path = os.path.join(output_directory, log_file)
        os.makedirs(output_directory, exist_ok=True)
        file_handler = logging.FileHandler(log_file_path, mode=log_mode, encoding='utf-8')
        file_handler.setFormatter(log_format)
        file_handler.setLevel(logging.DEBUG)
        logging.getLogger().addHandler(file_handler)

    if log_to_console:
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(console_log_format)
        console_handler.setLevel(logging.INFO)
        console_handler.setStream(open(1, 'w', encoding='utf-8', closefd=False))
        logging.getLogger().addHandler(console_handler)

    logging.getLogger().setLevel(logging.DEBUG)
    logging.getLogger('PIL').setLevel(logging.WARNING)



###### FILENAME: utils.py ######

import base64
import hashlib
import requests
import os
import logging
from functools import wraps

def safe_api_call(func):
    @wraps(func)
    def wrapper(*args, **kwargs):
        try:
            return func(*args, **kwargs)
        except requests.RequestException as e:
            logging.error(f"API request failed: {str(e)}")
            return {"error": str(e)}
        except Exception as e:
            logging.exception(f"Unexpected error in API call: {str(e)}")
            return {"error": "An unexpected error occurred"}
    return wrapper

def encode_image_to_base64(image_path):
    try:
        with open(image_path, "rb") as image_file:
            return base64.b64encode(image_file.read()).decode('utf-8')
    except FileNotFoundError:
        logging.error(f"Image file not found: {image_path}")
        return None
    except Exception as e:
        logging.exception(f"Error encoding image {image_path}: {str(e)}")
        return None

def generate_unique_code(file_path):
    try:
        with open(file_path, "rb") as f:
            file_hash = hashlib.blake2b()
            for chunk in iter(lambda: f.read(8192), b""):
                file_hash.update(chunk)
        return file_hash.hexdigest()
    except Exception as e:
        logging.exception(f"Error generating unique code for {file_path}: {str(e)}")
        return None

@safe_api_call
def analyze_image_detailed(image_base64, model, caption_types, api_url, timeout, config):
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {os.environ.get('OPENAI_API_KEY')}"
    }
    payload = {
        "model": model,
        "image": image_base64,
        "detailed": True,
        "caption_types": caption_types
    }
    response = requests.post(api_url, headers=headers, json=payload, timeout=timeout)
    response.raise_for_status()
    return response.json()

def get_existing_json_files(directory):
    existing_files = set()
    for root, _, files in os.walk(directory):
        for file in files:
            if file.endswith('.json'):
                existing_files.add(file)
    return existing_files

def setup_logging(level=logging.INFO):
    logging.basicConfig(
        level=level,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.StreamHandler(),
            logging.FileHandler('image_analysis.log')
        ]
    )

def validate_directory(directory):
    if not os.path.isdir(directory):
        raise ValueError(f"The specified path is not a valid directory: {directory}")
    if not os.access(directory, os.R_OK):
        raise PermissionError(f"You don't have read permissions for the directory: {directory}")

def validate_api_key():
    if 'OPENAI_API_KEY' not in os.environ:
        raise EnvironmentError("OPENAI_API_KEY environment variable is not set")


