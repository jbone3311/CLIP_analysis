## Directory Structure ##
./
    .gitignore
    analysis_main.py
    api_communication_log.json
    CodeSheetConfig.ini
    Code_From_analysis.txt
    Code_From_CWD.txt
    Code_From_utils.txt
    COMPLETE_CODE.TXT
    config.ini
    config.py
    constants.py
    Dir_Structure.txt
    LLM_CodeSheetV2.exe
    PreGITbak.zip
    test_llm.py
    analysis/
        clip_analysis.py
        llm_analysis.py
        test_process_llm_images.py
        __init__.py
    CODE_ data_analysis/
        data_analysis.py
    Images/
        1/
            RANDOS (30).png
            json/
                1_RANDOS (30)_clip_analysis.json
        2/
            FarSide (26).jpg
            RANDOS (20).png
            json/
                2_FarSide (26)_clip_analysis.json
                2_RANDOS (20)_clip_analysis.json
        test/
            FarSide (81).jpg
            sample.jpg
            json/
                test_FarSide (81)_clip_analysis.json
                test_sample_clip_analysis.json
    Output/
        api_communication_log.json
        Log.log
        CLIP_analysis/
            1_best_Prompts.txt
            1_caption_Prompts.txt
            1_classic_Prompts.txt
            1_fast_Prompts.txt
            1_negative_Prompts.txt
            2_best_Prompts.txt
            2_caption_Prompts.txt
            2_classic_Prompts.txt
            2_fast_Prompts.txt
            2_negative_Prompts.txt
            test_best_Prompts.txt
            test_caption_Prompts.txt
            test_classic_Prompts.txt
            test_fast_Prompts.txt
            test_negative_Prompts.txt
    test_images/
        test_subdir/
            test_image.jpg
            test_image.png
            json/
                test_subdir_test_image_llm_analysis.json
    utils/
        api_analysis.py
        api_utils.py
        image_utils.py
        json_utils.py
        logging_setup.py
        __init__.py

## Main Directory ##

###### FILENAME: analysis_main.py ######

import logging
import time
from config import Config
from utils.logging_setup import setup_logging
from analysis.clip_analysis import process_clip_images
from analysis.llm_analysis import process_llm_images
from utils.json_utils import process_existing_json_files
from utils.api_utils import test_api

def main():
    """
    Main function to run the analysis.
    """
    config = Config()
    setup_logging(config)

    logging.info("### Processing New Batch ###")

    # Verify the API before starting the image processing
    api_base_url = config.api_base_url
    timeout = config.timeout

    for attempt in range(3):
        if test_api(api_base_url, timeout):
            logging.info("API is responsive and working.")
            process_clip_images(config, api_base_url, timeout)
            process_llm_images(config, api_base_url, timeout)
            break
        else:
            logging.warning("API at %s is not responsive. Attempt %d failed.", api_base_url, attempt + 1)
            time.sleep(2 ** attempt)  # Exponential backoff
    else:
        logging.error("API at %s is not responsive after 3 attempts. Skipping.", api_base_url)

    # Process existing JSON files to generate prompt lists
    process_existing_json_files(config)

if __name__ == "__main__":
    main()


###### FILENAME: config.py ######

import logging
import os
import configparser
from constants import DEFAULTS

def mask_api_key(api_key):
    """Mask the API key for secure logging."""
    if len(api_key) < 6:
        return "*" * len(api_key)
    return api_key[:3] + "*" * (len(api_key) - 6) + api_key[-3:]

class Config:
    """
    Configuration handler to load and manage application settings.
    """

    def __init__(self, config_file='config.ini'):
        self.config_file = config_file
        self.config = configparser.RawConfigParser()
        self.load_config()

    def load_config(self):
        """
        Load configuration from the config file.
        """
        if not os.path.exists(self.config_file):
            self.create_default_config()
        self.config.read(self.config_file)

        # General Settings
        self.image_directory = self.config.get('DEFAULT', 'IMAGE_DIRECTORY', fallback=DEFAULTS['DEFAULT']['IMAGE_DIRECTORY'])
        self.output_directory = self.config.get('DEFAULT', 'OUTPUT_DIRECTORY', fallback=DEFAULTS['DEFAULT']['OUTPUT_DIRECTORY'])
        self.api_base_url = self.config.get('DEFAULT', 'API_BASE_URL', fallback=DEFAULTS['DEFAULT']['API_BASE_URL'])
        self.api_key = self.get_openai_api_key()
        self.timeout = self.config.getint('DEFAULT', 'TIMEOUT', fallback=DEFAULTS['DEFAULT']['TIMEOUT'])

        # Logging Settings
        self.logging_level = self.config.get('DEFAULT', 'LOGGING_LEVEL', fallback=DEFAULTS['DEFAULT']['LOGGING_LEVEL'])
        self.logging_format = self.config.get('DEFAULT', 'LOGGING_FORMAT', fallback=DEFAULTS['DEFAULT']['LOGGING_FORMAT'])
        self.log_to_console = self.config.getboolean('DEFAULT', 'LOG_TO_CONSOLE', fallback=DEFAULTS['DEFAULT']['LOG_TO_CONSOLE'])
        self.log_to_file = self.config.getboolean('DEFAULT', 'LOG_TO_FILE', fallback=DEFAULTS['DEFAULT']['LOG_TO_FILE'])
        self.log_file = self.config.get('DEFAULT', 'LOG_FILE', fallback=DEFAULTS['DEFAULT']['LOG_FILE'])
        self.log_mode = self.config.get('DEFAULT', 'LOG_MODE', fallback=DEFAULTS['DEFAULT']['LOG_MODE'])
        self.log_api_communication = self.config.getboolean('DEFAULT', 'LOG_API_COMMUNICATION', fallback=DEFAULTS['DEFAULT']['LOG_API_COMMUNICATION'])

        # File Handling Settings
        self.create_individual_files = self.config.getboolean('DEFAULT', 'CREATE_INDIVIDUAL_FILES', fallback=DEFAULTS['DEFAULT']['CREATE_INDIVIDUAL_FILES'])
        self.create_prompt_list = self.config.getboolean('DEFAULT', 'CREATE_PROMPT_LIST', fallback=DEFAULTS['DEFAULT']['CREATE_PROMPT_LIST'])
        self.create_master_files = self.config.getboolean('DEFAULT', 'CREATE_MASTER_FILES', fallback=DEFAULTS['DEFAULT']['CREATE_MASTER_FILES'])
        self.list_file_mode = self.config.get('DEFAULT', 'LIST_FILE_MODE', fallback=DEFAULTS['DEFAULT']['LIST_FILE_MODE'])

        # Model Settings
        self.model = self.config.get('DEFAULT', 'MODEL', fallback=DEFAULTS['DEFAULT']['MODEL'])
        self.model_nickname = self.config.get('DEFAULT', 'MODEL_NICKNAME', fallback=self.model)
        self.caption_types = self.get_config_list('CAPTION_TYPES')

        # Filename-related variables
        self.master_analysis_filename = self.config.get('DEFAULT', 'MASTER_ANALYSIS_FILENAME', fallback=DEFAULTS['DEFAULT']['MASTER_ANALYSIS_FILENAME'])

        # New option for processing JSON files without images
        self.process_json_without_images = self.config.getboolean('DEFAULT', 'PROCESS_JSON_WITHOUT_IMAGES', fallback=DEFAULTS['DEFAULT']['PROCESS_JSON_WITHOUT_IMAGES'])

        # LLM Settings
        self.selected_prompts = self.get_config_list('SELECTED_PROMPT')
        self.llm_system_content = self.config.get('DEFAULT', 'LLM_SYSTEM_CONTENT', fallback=DEFAULTS['DEFAULT']['LLM_SYSTEM_CONTENT'])
        self.llm_model = self.config.get('DEFAULT', 'LLM_MODEL', fallback=DEFAULTS['DEFAULT']['LLM_MODEL'])

        # Multiple LLMs configuration
        self.llms = {}
        for i in range(2, 5):  # Assuming we have up to 4 LLMs, with OpenAI hardcoded as the first
            llm_key = f'LLM_{i}'
            if self.config.has_section(llm_key):
                self.llms[llm_key] = {
                    'enabled': self.config.getboolean(llm_key, 'ENABLED', fallback=False),
                    'api_url': self.config.get(llm_key, 'API_URL', fallback=''),
                    'api_key': self.config.get(llm_key, 'API_KEY', fallback='')
                }
                logging.debug("LLM configuration for %s: %s" % (llm_key, self.llms[llm_key]))

    def get_config_list(self, key):
        """
        Get a list of values from a comma-separated config entry.

        :param key: Configuration key.
        :return: List of values.
        """
        return [item.strip() for item in self.config.get('DEFAULT', key, fallback='').split(',')]

    def create_default_config(self):
        """
        Create a default configuration file if it does not exist.
        """
        with open(self.config_file, 'w', encoding='utf-8') as configfile:
            for section, options in DEFAULTS.items():
                configfile.write(f"[{section}]\n")
                for key, value in options.items():
                    configfile.write(f"{key} = {value}\n")
                configfile.write("\n")
        self.config.read(self.config_file)

    def get_openai_api_key(self):
        """
        Get the OpenAI API key from the environment variable.
        """
        api_key = os.getenv('OPENAI_API_KEY', '')
        if not api_key:
            logging.error("OpenAI API Key not found in environment.")
        logging.debug(f"Fetched OpenAI API Key: {mask_api_key(api_key)}")
        return api_key


###### FILENAME: constants.py ######

DEFAULTS = {
    'DEFAULT': {
        'IMAGE_DIRECTORY': 'Images',
        'OUTPUT_DIRECTORY': 'Output',
        'API_BASE_URL': 'http://127.0.0.1:7864',
        'API_KEY': '',
        'TIMEOUT': 40,
        'LOGGING_LEVEL': 'DEBUG',
        'LOGGING_FORMAT': '%(message)s',
        'LOG_TO_CONSOLE': True,
        'LOG_TO_FILE': True,
        'LOG_FILE': 'Log.log',
        'LOG_MODE': 'w',
        'LOG_API_COMMUNICATION': True,
        'MODEL': 'ViT-g-14/laion2B-s34B-b88K',
        'CAPTION_TYPES': 'caption,best,fast,classic,negative',
        'ANALYSIS_TYPE': 1,
        'LLM_API_BASE_URL': 'https://api.openai.com/v1/chat/completions',
        'LLM_API_KEY': '',
        'LLM_API_HEADERS': '{"Content-Type": "application/json"}',
        'LLM_SYSTEM_CONTENT': 'Your default system content here',
        'LLM_MODEL': 'gpt-4o',  # Default LLM model
        'SELECTED_PROMPT': 1,
        'IMAGE_FILE_EXTENSIONS': '.png,.jpg,.jpeg',
        'CREATE_INDIVIDUAL_FILES': True,  # Ensure this key is included
        'CREATE_PROMPT_LIST': True,
        'CREATE_MASTER_FILES': True,
        'LIST_FILE_MODE': 'w',
        'MASTER_ANALYSIS_FILENAME': 'master_analysis.json',
        'PROCESS_JSON_WITHOUT_IMAGES': False
    },
    'Prompt Options': {
        '1': {
            'PROCESS_NAME': 'DetailedDescription',
            'PROMPT_TEXT': (
                "Provide a detailed description of the image's content, focusing on essential elements such as key figures, objects, setting, and any significant interactions. "
                "You should not mention anything associated with style like colors, artist names or techniques. "
                "Just describe what is happening in the scene. Ensure the description is clear and comprehensive enough for someone who has never seen the image to accurately recreate it in a painting. "
                "Each answer should be one paragraph per image only."
            ),
            'TEMPERATURE': 0.7,
            'MAX_TOKENS': 100
        },
        '2': {
            'PROCESS_NAME': 'EnhanceDetails',
            'PROMPT_TEXT': "Enhance the image details, making colors more vibrant and edges sharper.",
            'TEMPERATURE': 0.6,
            'MAX_TOKENS': 150
        },
        '3': {
            'PROCESS_NAME': 'ObjectInteraction',
            'PROMPT_TEXT': "Remove any style or art references from the image description, focusing purely on the objects and interactions.",
            'TEMPERATURE': 0.5,
            'MAX_TOKENS': 200
        },
        '4': {
            'PROCESS_NAME': 'DeepDescription',
            'PROMPT_TEXT': "Provide a deep description of the image, including subtle details and background elements.",
            'TEMPERATURE': 0.8,
            'MAX_TOKENS': 250
        },
        '5': {
            'PROCESS_NAME': 'HistoricalAnalysis',
            'PROMPT_TEXT': "Analyze the image for any historical or cultural references, providing context and background information.",
            'TEMPERATURE': 0.9,
            'MAX_TOKENS': 300
        }
    },
    'LLM_1': {
        'ENABLED': True,
        'API_URL': 'https://api.openai.com/v1/chat/completions',
        'API_KEY': ''  # Will be fetched from the environment variable 'OPENAI_API_KEY'
    },
    'LLM_2': {
        'ENABLED': False,
        'API_URL': 'https://example.com/api1',
        'API_KEY': ''
    },
    'LLM_3': {
        'ENABLED': False,
        'API_URL': 'https://example.com/api2',
        'API_KEY': ''
    },
    'LLM_4': {
        'ENABLED': False,
        'API_URL': 'https://example.com/api3',
        'API_KEY': ''
    }
}



###### FILENAME: test_llm.py ######

import os
import base64
import json
import logging
import requests

# Set up logging for the test
logging.basicConfig(level=logging.DEBUG)

# Test configuration
TEST_OPENAI_API_KEY = os.getenv('TEST_OPENAI_API_KEY', 'sk-proj-CSugxHuYq4dgiIEJjQo3T3BlbkFJimzWdOKu0UR9ZbHYvT2W')  # Replace with your actual OpenAI API key
TEST_IMAGE_PATH = r"C:\Users\jiml\Dropbox\#AIArt\SourceCode\CODE_CLIP_Analysis\Images\1\RANDOS (30).png"
TEST_PROMPT_TEXT = "What's in this image?"
TEST_MODEL = "gpt-4o"
TEST_TEMPERATURE = 0.7
TEST_MAX_TOKENS = 300

def encode_image(image_path):
    """Encode an image file to a base64 string."""
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode('utf-8')

def test_llm_analysis():
    # Set the OpenAI API key in environment variable
    os.environ['OPENAI_API_KEY'] = TEST_OPENAI_API_KEY

    # Encode the image to base64
    base64_image = encode_image(TEST_IMAGE_PATH)

    # Create the headers
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {os.getenv('OPENAI_API_KEY')}"
    }

    # Create the data payload
    payload = {
        "model": TEST_MODEL,
        "messages": [
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": TEST_PROMPT_TEXT},
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/jpeg;base64,{base64_image}"
                        }
                    }
                ]
            }
        ],
        "temperature": TEST_TEMPERATURE,
        "max_tokens": TEST_MAX_TOKENS,
        "top_p": 1.0,
        "frequency_penalty": 0.0,
        "presence_penalty": 0.0
    }

    # Log the data payload excluding the 'messages' content
    logging.debug(f"Created data payload for LLM request: {json.dumps({k: v for k, v in payload.items() if k != 'messages'}, indent=2)}")

    # Send the request
    response = requests.post("https://api.openai.com/v1/chat/completions", headers=headers, json=payload)

    # Print the response
    if response.status_code == 200:
        print("Response received:")
        print(response.json())
    else:
        logging.error(f"Request failed: {response.json()}")
        print("No response received.")

if __name__ == "__main__":
    test_llm_analysis()



## analysis ##

###### FILENAME: clip_analysis.py ######

import os
import sys

# Add the parent directory to the Python path
parent_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(parent_dir)

import logging
import time
from utils.image_utils import encode_image_to_base64, generate_unique_code
from utils.json_utils import save_json, get_existing_json_files
from utils.api_utils import analyze_image_detailed
from constants import DEFAULTS

def process_clip_images(config, api_url, timeout):
    """
    Process images in a directory and send them for CLIP analysis.

    Args:
        config: Configuration object.
        api_url: Base URL of the API.
        timeout: Timeout duration for the request.
    """
    failed_images = []
    images_to_process = []
    existing_json_files = []

    # Traverse the image directory and its subdirectories
    for subdir in os.listdir(config.image_directory):
        subdir_path = os.path.join(config.image_directory, subdir)
        if os.path.isdir(subdir_path):
            logging.debug(f"Looking into directory: {subdir_path}")
            batch_json_dir = os.path.join(subdir_path, 'json')
            os.makedirs(batch_json_dir, exist_ok=True)

            # Get existing JSON files
            existing_json_files += get_existing_json_files(batch_json_dir)

            for root, _, files in os.walk(subdir_path):
                logging.debug(f"Processing images in directory: {root}")
                image_files = [file for file in files if file.lower().endswith(('.png', '.jpg', '.jpeg'))]
                for file in image_files:
                    images_to_process.append((root, file, batch_json_dir, subdir))

    total_images = len(images_to_process)
    if total_images == 0:
        logging.info("No images found to process.")
        return failed_images

    logging.info(f"Total images to process: {total_images}")

    # Initialize counters and timers
    image_counter = len(existing_json_files)
    total_processing_time = 0

    for root, file, batch_json_dir, subdir in images_to_process:
        clip_json_output_filename = f"{subdir}_{os.path.splitext(file)[0]}_clip_analysis.json"
        clip_json_full_path = os.path.join(batch_json_dir, clip_json_output_filename)
        
        # Initialize the result dictionary
        detailed_results = {
            'filename': file,
            'unique_code': generate_unique_code(os.path.join(root, file)),
            'directory_name': subdir,
            'model': config.model,
            'prompts': {},
            'analysis': {}
        }

        # Process CLIP analysis only if the JSON file does not exist
        if clip_json_output_filename not in existing_json_files:
            image_counter += 1
            logging.info(f"{file} - {image_counter}/{total_images + len(existing_json_files)}")
            file_path = os.path.join(root, file)
            image_base64 = encode_image_to_base64(file_path)

            if image_base64 is None:
                logging.error(f"Failed to encode image: {file_path}")
                failed_images.append(file_path)
                continue

            # Start timing the processing
            start_time = time.time()

            # Analyze the image in detail
            detailed_results.update(analyze_image_detailed(image_base64, config.model, config.caption_types, api_url, timeout, config))

            # Calculate processing time
            processing_time = time.time() - start_time
            total_processing_time += processing_time

            # Display processing time and estimated remaining time
            average_processing_time = total_processing_time / (image_counter - len(existing_json_files))
            remaining_time = average_processing_time * (total_images + len(existing_json_files) - image_counter)
            logging.info(f"Processing time for {file}: {processing_time:.2f} seconds")
            logging.info(f"Estimated remaining time: {remaining_time:.2f} seconds")

            # Save the combined JSON result
            try:
                save_json(clip_json_full_path, detailed_results)
                logging.info(f"JSON output created: {clip_json_full_path}")
            except Exception as e:
                logging.error(f"Failed to save JSON for {file}: {e}")
                failed_images.append(file_path)

    if failed_images:
        logging.error(f"Failed to process the following images: {failed_images}")

    logging.info("Image processing completed successfully.")
    return failed_images


###### FILENAME: llm_analysis.py ######

import json
import os
import logging
from config import mask_api_key
from utils.image_utils import encode_image_to_base64, generate_unique_code
from utils.json_utils import save_json, get_existing_json_files
from utils.api_utils import send_llm_request, is_llm_json_valid, create_data
from constants import DEFAULTS

def process_llm_images(config, api_url, timeout):
    """
    Process images in a directory and send them for LLM analysis.

    Args:
        config: Configuration object.
        api_url: Base URL of the API.
        timeout: Timeout duration for the request.
    """
    failed_images = []
    images_to_process = []
    existing_json_files = []

    # Traverse the image directory and its subdirectories
    for subdir in os.listdir(config.image_directory):
        subdir_path = os.path.join(config.image_directory, subdir)
        if os.path.isdir(subdir_path):
            logging.debug(f"Looking into directory: {subdir_path}")
            batch_json_dir = os.path.join(subdir_path, 'json')
            os.makedirs(batch_json_dir, exist_ok=True)

            # Get existing JSON files
            existing_json_files += get_existing_json_files(batch_json_dir)

            for root, _, files in os.walk(subdir_path):
                logging.debug(f"Processing images in directory: {root}")
                image_files = [file for file in files if file.lower().endswith(('.png', '.jpg', '.jpeg'))]
                for file in image_files:
                    images_to_process.append((root, file, batch_json_dir, subdir))

    total_images = len(images_to_process)
    if total_images == 0:
        logging.info("No images found to process.")
        return failed_images

    logging.info(f"Total images to process: {total_images}")

    # Initialize counters and timers
    image_counter = len(existing_json_files)
    total_processing_time = 0

    for root, file, batch_json_dir, subdir in images_to_process:
        llm_json_output_filename = f"{subdir}_{os.path.splitext(file)[0]}_llm_analysis.json"
        llm_json_full_path = os.path.join(batch_json_dir, llm_json_output_filename)

        # Process LLM analysis only if the JSON file does not exist
        if llm_json_output_filename not in existing_json_files:
            logging.info(f"LLM JSON file is invalid or does not exist for {file}. Running LLM analysis.")
            llm_results = {}

            # Hardcoded OpenAI settings
            openai_enabled = config.llms.get('LLM_1', {}).get('enabled', False)
            if openai_enabled:
                logging.info(f"Running LLM analysis using OpenAI for {file}.")
                for prompt_id in config.selected_prompts:
                    image_base64 = encode_image_to_base64(os.path.join(root, file))
                    data = {
                        "model": config.llm_model,
                        "messages": [
                            {
                                "role": "user",
                                "content": [
                                    {"type": "text", "text": DEFAULTS['Prompt Options'][prompt_id]['PROMPT_TEXT']},
                                    {
                                        "type": "image_url",
                                        "image_url": {
                                            "url": f"data:image/jpeg;base64,{image_base64}"
                                        }
                                    }
                                ]
                            }
                        ],
                        "temperature": DEFAULTS['Prompt Options'][prompt_id]['TEMPERATURE'],
                        "max_tokens": DEFAULTS['Prompt Options'][prompt_id]['MAX_TOKENS'],
                        "top_p": 1.0,
                        "frequency_penalty": 0.0,
                        "presence_penalty": 0.0
                    }
                    logging.debug(f"Sending LLM request for prompt ID {prompt_id}")
                    logging.debug(f"Data payload: {json.dumps(data, indent=2)}")
                    api_key = config.get_openai_api_key()
                    logging.debug(f"Using API Key: {mask_api_key(api_key)}")
                    response = send_llm_request(data, api_key)
                    if response:
                        logging.debug(f"Received response for prompt ID {prompt_id}")
                        llm_results[prompt_id] = response['choices'][0]['message']['content']
                    else:
                        logging.warning(f"No response received for prompt ID {prompt_id}.")
                        llm_results[prompt_id] = None

            # Additional LLMs from config
            for llm_key, llm_config in config.llms.items():
                if llm_key != 'LLM_1' and llm_config['enabled']:
                    for prompt_id in config.selected_prompts:
                        image_base64 = encode_image_to_base64(os.path.join(root, file))
                        data = {
                            "model": config.llm_model,
                            "messages": [
                                {
                                    "role": "user",
                                    "content": [
                                        {"type": "text", "text": DEFAULTS['Prompt Options'][prompt_id]['PROMPT_TEXT']},
                                        {
                                            "type": "image_url",
                                            "image_url": {
                                                "url": f"data:image/jpeg;base64,{image_base64}"
                                            }
                                        }
                                    ]
                                }
                            ],
                            "temperature": DEFAULTS['Prompt Options'][prompt_id]['TEMPERATURE'],
                            "max_tokens": DEFAULTS['Prompt Options'][prompt_id]['MAX_TOKENS'],
                            "top_p": 1.0,
                            "frequency_penalty": 0.0,
                            "presence_penalty": 0.0
                        }
                        logging.debug(f"Sending LLM request for prompt ID {prompt_id}")
                        logging.debug(f"Data payload: {json.dumps(data, indent=2)}")
                        logging.debug(f"Using API Key: {mask_api_key(llm_config['api_key'])}")
                        response = send_llm_request(data, llm_config['api_key'])
                        if response:
                            logging.debug(f"Received response for prompt ID {prompt_id}")
                            llm_results[prompt_id] = response['choices'][0]['message']['content']
                        else:
                            logging.warning(f"No response received for prompt ID {prompt_id}.")
                            llm_results[prompt_id] = None

            # Check if llm_results is not empty before saving
            if llm_results:
                try:
                    save_json(llm_json_full_path, llm_results)
                except Exception as e:
                    logging.error(f"Failed to save LLM JSON for {file}: {e}")
                    failed_images.append(file)
            else:
                logging.info(f"No LLM results for {file}. Skipping saving LLM JSON.")

    if failed_images:
        logging.error(f"Failed to process the following images: {failed_images}")

    logging.info("LLM analysis completed successfully.")
    return failed_images


###### FILENAME: test_process_llm_images.py ######

import os
import sys
import json
import logging
import unittest

# Add the parent directory to the Python path
parent_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(parent_dir)

from config import Config
from utils.image_utils import encode_image_to_base64
from utils.json_utils import save_json, get_existing_json_files
from utils.api_utils import send_llm_request
from constants import DEFAULTS
from analysis.llm_analysis import process_llm_images

# Test configuration variables
TEST_IMAGE_DIRECTORY = 'test_images'
TEST_SUBDIR = 'test_subdir'
TEST_IMAGE_PATH = r"C:\Users\jiml\Dropbox\#AIArt\SourceCode\CODE_CLIP_Analysis\Images\2\RANDOS (20).png"
REAL_IMAGE_DIRECTORY = 'real_images'  # Placeholder for the real directory path

class TestProcessLLMImages(unittest.TestCase):

    def test_process_llm_images(self):
        # Fetch the API key from the environment variable
        api_key = os.getenv('OPENAI_API_KEY')
        if not api_key:
            self.fail("Environment variable 'OPENAI_API_KEY' is not set.")

        # Set up a test configuration
        config = Config()
        config.image_directory = TEST_IMAGE_DIRECTORY
        config.llms = {
            'LLM_1': {
                'enabled': True,
                'api_url': 'https://api.openai.com/v1/chat/completions',
                'api_key': api_key
            }
        }
        config.selected_prompts = ['1']

        # Create test image directory and files
        os.makedirs(os.path.join(TEST_IMAGE_DIRECTORY, TEST_SUBDIR, 'json'), exist_ok=True)
        with open(os.path.join(TEST_IMAGE_DIRECTORY, TEST_SUBDIR, 'test_image.png'), 'wb') as f:
            f.write(open(TEST_IMAGE_PATH, 'rb').read())

        # Run the function
        failed_images = process_llm_images(config, 'https://api.openai.com/v1/chat/completions', 30)

        # Check results
        self.assertFalse(failed_images, "There should be no failed images")

        # Clean up
        os.remove(os.path.join(TEST_IMAGE_DIRECTORY, TEST_SUBDIR, 'test_image.png'))
        os.rmdir(os.path.join(TEST_IMAGE_DIRECTORY, TEST_SUBDIR, 'json'))
        os.rmdir(os.path.join(TEST_IMAGE_DIRECTORY, TEST_SUBDIR))
        os.rmdir(TEST_IMAGE_DIRECTORY)

def real_api_test():
    # Fetch the API key from the environment variable
    api_key = os.getenv('OPENAI_API_KEY')
    if not api_key:
        logging.error("Environment variable 'OPENAI_API_KEY' is not set.")
        return

    # Ensure the real image directory exists
    if not os.path.exists(REAL_IMAGE_DIRECTORY):
        logging.error(f"Directory '{REAL_IMAGE_DIRECTORY}' does not exist.")
        return

    # Set up a real configuration
    config = Config()
    config.image_directory = REAL_IMAGE_DIRECTORY
    config.llms = {
        'LLM_1': {
            'enabled': True,
            'api_url': 'https://api.openai.com/v1/chat/completions',
            'api_key': api_key
        }
    }
    config.selected_prompts = ['1']

    # Run the function with real data
    failed_images = process_llm_images(config, 'https://api.openai.com/v1/chat/completions', 30)

    if not failed_images:
        logging.info("Real API test completed successfully without errors.")
    else:
        logging.error(f"Real API test failed for the following images: {failed_images}")

if __name__ == "__main__":
    logging.basicConfig(level=logging.DEBUG)
    # Uncomment the following line to run the real API test
    real_api_test()


###### FILENAME: __init__.py ######

# analysis/__init__.py
# This file ensures the `analysis` subdirectory is treated as a package.


