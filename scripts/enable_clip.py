#!/usr/bin/env python3
"""
Enable CLIP Analysis
"""

import os
import subprocess
import sys
import time

def enable_clip_analysis():
    """Enable CLIP analysis by setting environment variable"""
    print("Enabling CLIP Analysis...")
    
    # Set environment variable
    os.environ['ENABLE_CLIP_ANALYSIS'] = 'True'
    
    # Create or update .env file
    env_content = """# Image Analysis Configuration
# Generated by enable_clip.py

# Processing Settings
ENABLE_CLIP_ANALYSIS=True
ENABLE_LLM_ANALYSIS=True
ENABLE_METADATA_EXTRACTION=True
FORCE_REPROCESS=False
GENERATE_SUMMARIES=True

# API Configuration
API_BASE_URL=http://localhost:7860

# CLIP Interrogator Settings
CLIP_MODEL_NAME=ViT-L-14/openai
CLIP_MODES=best,fast,classic,negative,caption

# LLM Settings
PROMPT_CHOICES=P1,P2

# General Settings
IMAGE_DIRECTORY=Images
OUTPUT_DIRECTORY=Output
LOGGING_LEVEL=INFO
RETRY_LIMIT=5
TIMEOUT=300

# Status Messages
EMOJI_SUCCESS=SUCCESS
EMOJI_WARNING=WARNING
EMOJI_ERROR=ERROR
EMOJI_INFO=INFO
EMOJI_PROCESSING=PROCESSING
EMOJI_START=START
EMOJI_COMPLETE=COMPLETE
"""
    
    with open('.env', 'w', encoding='utf-8') as f:
        f.write(env_content)
    
    print("CLIP Analysis enabled!")
    print("Configuration saved to .env file")
    print("Web interface should now use CLIP analysis")
    print("\nYou can now:")
    print("   1. Go to http://localhost:5050")
    print("   2. Click 'Process Images'")
    print("   3. CLIP analysis will be enabled")

if __name__ == "__main__":
    enable_clip_analysis() 